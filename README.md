# ICU Time Series Analysis: Predictive Modeling and Representation Learning

<a target="_blank" href="https://cookiecutter-data-science.drivendata.org/">
    <img src="https://img.shields.io/badge/CCDS-Project%20template-328F97?logo=cookiecutter" />
</a>

## Abstract

Intensive care patients, usually being severely ill, are closely monitored by state of the art
medical devices and sensors to measure vital signs at regular intervals. Additionally, doctors
take frequent laboratory tests and any type of treatment administered via infusion, injection,
or oxygen supplied through various ventilation equipment, are all meticulously recorded.

These large amounts of data can be overwhelming for intensive care physicians to analyze
properly while under time pressure. Machine learning algorithms are prime candidates to
leverage these large amounts of data and distill them into actionable outputs for clinical
decision support.

The goal of this project is to get familiar with such a promising type of healthcare data, while
at the same time learning how to tackle the challenges of working on noisy, multi-variate,
irregularly-sampled and sparse, and confounded real world data.

## ðŸ“¦ Project Organization

```
â”œâ”€â”€ LICENSE            <- Open-source license if one is chosen
â”œâ”€â”€ Makefile           <- Makefile with convenience commands like `make data` or `make train`
â”œâ”€â”€ README.md          <- The top-level README for developers using this project.
â”‚
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ data_1         <- Contains the initial raw data from the challenge.
â”‚   â””â”€â”€ processed      <- The final, cleaned data used for modeling.
â”‚
â”œâ”€â”€ docs               <- Documentation files for the project
â”‚   â”œâ”€â”€ Project 1 - ICU Time Series - Handout.pdf
â”‚   â””â”€â”€ Project 1 - ICU Time Series - Slides.pdf
â”‚
â”œâ”€â”€ models             <- Trained models, predictions, or model summaries
â”‚
â”œâ”€â”€ notebooks          <- Jupyter notebooks. Naming convention is a number (for ordering),
â”‚                         the creator's initials, and a short `-` delimited description, e.g.
â”‚                         `1.0-jqp-initial-data-exploration`.
â”‚
â”œâ”€â”€ pyproject.toml     <- Project configuration file with package metadata for
â”‚                         project_1 and configuration for tools like black
â”‚
â”œâ”€â”€ references         <- Data dictionaries, manuals, and other reference materials.
â”‚
â”œâ”€â”€ reports            <- Generated analysis as HTML, PDF, LaTeX, etc.
â”‚   â””â”€â”€ figures        <- Generated figures for reporting and presentations
â”‚
â”œâ”€â”€ requirements.txt   <- The requirements file to reproduce the analysis environment
â”‚
â”œâ”€â”€ setup.cfg          <- Configuration file for linting tools like flake8
â”‚
â”œâ”€â”€ scripts            <- Shell scripts or utilities for automation
â”‚   â””â”€â”€ run_Q1_data_processing.sh  <- Script to execute all Q1 processing steps
â”‚
â””â”€â”€ project_1          <- Python module containing the core logic for the project
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ Q1/            <- Code for Question 1 (e.g., preprocessing, cleaning)
    â”œâ”€â”€ Q2/            <- Code for Question 2 (e.g., tokenization, embeddings)
    â”œâ”€â”€ Q4/            <- Code for Question 4 (e.g., classifier training)
    â”œâ”€â”€ loading.py     <- Functions to load raw and processed data
    â”œâ”€â”€ features.py    <- Functions for feature scaling and preprocessing
    â””â”€â”€ dataset.py     <- Functions to convert data into PyTorch datasets

```

---

## âš™ï¸ Setup

Install dependencies (recommended via virtual environment):

```
pip install -r requirements.txt
```

### âš ï¸ Ollama Note

This project uses the ollama Python package to interface with locally running language models. Please ensure that Ollama is installed on your device before using this featureâ€”otherwise, the Python package will not function correctly.
You can follow the installation guide here: https://ollama.com/download

---

## ðŸš€ How to Run the Project

This project is organized into four main questions (Q1â€“Q4), each addressing a different part of ICU time-series analysis. Follow the instructions below to reproduce the results.

---

### ðŸ“Š Q1: Data Preprocessing

1. Download the challenge dataset from PhysioNet:  
   [`predicting-mortality-of-icu-patients-the-physionet-computing-in-cardiology-challenge-2012-1.0.0`](https://physionet.org/content/challenge-2012/1.0.0/)

2. Place the extracted folder inside:

   ```
   data/data_1/
   ```

3. Run the preprocessing script to clean and process the raw data:

   ```
   bash scripts/run_Q1_data_processing.sh
   ```

   This will generate all necessary `.parquet` files inside:

   ```
   data/processed/
   ```

---

### ðŸ¤– Q2: Supervised Learning

Explore different supervised learning models and results in the following notebook:

ðŸ““ `notebooks/2_Q2_supervised_learning.ipynb`

---

### ðŸ¤¯ Q3: Representation Learning

Dive into self-supervised learning and contrastive representation learning in:

ðŸ““ `notebooks/3_Q3_representation_learning.ipynb`

---

### ðŸ§  Q4: Foundation Models

Analyze foundation model performance and transfer learning setups in:

ðŸ““ `notebooks/4_Q4_foundation_models.ipynb`
