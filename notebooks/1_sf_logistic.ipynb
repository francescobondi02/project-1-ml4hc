{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2.1 Classic Machine Learning Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-26 15:39:58.582\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproject_1.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mPROJ_ROOT path is: /Users/francescobondi/Desktop/stuff/ETH/FS25/ML for Healthcare/project-1-ml4hc\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from project_1.config import PROCESSED_DATA_DIR, PROJ_ROOT\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(196000, 43)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordID</th>\n",
       "      <th>Time</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Age</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>DiasABP</th>\n",
       "      <th>HCO3</th>\n",
       "      <th>...</th>\n",
       "      <th>Urine</th>\n",
       "      <th>WBC</th>\n",
       "      <th>pH</th>\n",
       "      <th>MechVent</th>\n",
       "      <th>TroponinT</th>\n",
       "      <th>ALP</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AST</th>\n",
       "      <th>Bilirubin</th>\n",
       "      <th>TroponinI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>132539.0</td>\n",
       "      <td>2025-03-10 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.950365</td>\n",
       "      <td>-0.231946</td>\n",
       "      <td>-0.583612</td>\n",
       "      <td>1.452191</td>\n",
       "      <td>-0.133234</td>\n",
       "      <td>-0.810049</td>\n",
       "      <td>-0.037519</td>\n",
       "      <td>...</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.318841</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.314286</td>\n",
       "      <td>0.189655</td>\n",
       "      <td>-0.307692</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132539.0</td>\n",
       "      <td>2025-03-10 01:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.950365</td>\n",
       "      <td>-0.231946</td>\n",
       "      <td>-0.583612</td>\n",
       "      <td>0.171208</td>\n",
       "      <td>-0.693421</td>\n",
       "      <td>0.634509</td>\n",
       "      <td>-2.669841</td>\n",
       "      <td>...</td>\n",
       "      <td>3.076923</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>-0.625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.571429</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>1.557692</td>\n",
       "      <td>-0.240741</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>-0.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>132539.0</td>\n",
       "      <td>2025-03-10 02:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.950365</td>\n",
       "      <td>-0.231946</td>\n",
       "      <td>-0.583612</td>\n",
       "      <td>1.025197</td>\n",
       "      <td>0.856429</td>\n",
       "      <td>0.937401</td>\n",
       "      <td>-0.256879</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.384615</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>2.120690</td>\n",
       "      <td>-0.461538</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>-0.178571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132539.0</td>\n",
       "      <td>2025-03-10 03:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.950365</td>\n",
       "      <td>-0.231946</td>\n",
       "      <td>-0.583612</td>\n",
       "      <td>-0.398117</td>\n",
       "      <td>2.761064</td>\n",
       "      <td>0.587911</td>\n",
       "      <td>-0.037519</td>\n",
       "      <td>...</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>-0.594203</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.942857</td>\n",
       "      <td>0.534483</td>\n",
       "      <td>51.769231</td>\n",
       "      <td>-0.259259</td>\n",
       "      <td>22.750000</td>\n",
       "      <td>0.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132539.0</td>\n",
       "      <td>2025-03-10 04:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.950365</td>\n",
       "      <td>-0.231946</td>\n",
       "      <td>-0.583612</td>\n",
       "      <td>-0.540449</td>\n",
       "      <td>-0.002524</td>\n",
       "      <td>0.937401</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.153846</td>\n",
       "      <td>-0.028986</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>-0.224138</td>\n",
       "      <td>-0.096154</td>\n",
       "      <td>-0.018519</td>\n",
       "      <td>1.416667</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>132539.0</td>\n",
       "      <td>2025-03-10 05:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.950365</td>\n",
       "      <td>-0.231946</td>\n",
       "      <td>-0.583612</td>\n",
       "      <td>-0.113454</td>\n",
       "      <td>-1.365645</td>\n",
       "      <td>-0.320763</td>\n",
       "      <td>-0.914959</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.153846</td>\n",
       "      <td>-0.637681</td>\n",
       "      <td>-0.875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.028571</td>\n",
       "      <td>2.189655</td>\n",
       "      <td>-0.403846</td>\n",
       "      <td>-0.240741</td>\n",
       "      <td>-0.583333</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>132539.0</td>\n",
       "      <td>2025-03-10 06:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.950365</td>\n",
       "      <td>-0.231946</td>\n",
       "      <td>-0.583612</td>\n",
       "      <td>1.167528</td>\n",
       "      <td>-0.133234</td>\n",
       "      <td>-0.285814</td>\n",
       "      <td>-1.792400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.884058</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.085714</td>\n",
       "      <td>-0.189655</td>\n",
       "      <td>-0.057692</td>\n",
       "      <td>-0.314815</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>132539.0</td>\n",
       "      <td>2025-03-10 07:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.950365</td>\n",
       "      <td>-0.231946</td>\n",
       "      <td>-0.583612</td>\n",
       "      <td>-0.682780</td>\n",
       "      <td>1.453962</td>\n",
       "      <td>0.937401</td>\n",
       "      <td>-0.914959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>-0.623188</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.228571</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.173077</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>1.035714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>132539.0</td>\n",
       "      <td>2025-03-10 08:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.950365</td>\n",
       "      <td>-0.231946</td>\n",
       "      <td>-0.583612</td>\n",
       "      <td>1.167528</td>\n",
       "      <td>-0.898823</td>\n",
       "      <td>-0.600355</td>\n",
       "      <td>0.401202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>-0.173913</td>\n",
       "      <td>-1.250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>-0.482759</td>\n",
       "      <td>3.538462</td>\n",
       "      <td>-0.203704</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.392857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>132539.0</td>\n",
       "      <td>2025-03-10 09:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.950365</td>\n",
       "      <td>-0.231946</td>\n",
       "      <td>-0.583612</td>\n",
       "      <td>0.171208</td>\n",
       "      <td>-0.394655</td>\n",
       "      <td>1.776177</td>\n",
       "      <td>1.278643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.285714</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>-0.461538</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>30.666667</td>\n",
       "      <td>-0.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RecordID                Time  Gender    Height    Weight       Age  \\\n",
       "0  132539.0 2025-03-10 00:00:00     0.0 -0.950365 -0.231946 -0.583612   \n",
       "1  132539.0 2025-03-10 01:00:00     0.0 -0.950365 -0.231946 -0.583612   \n",
       "2  132539.0 2025-03-10 02:00:00     0.0 -0.950365 -0.231946 -0.583612   \n",
       "3  132539.0 2025-03-10 03:00:00     0.0 -0.950365 -0.231946 -0.583612   \n",
       "4  132539.0 2025-03-10 04:00:00     0.0 -0.950365 -0.231946 -0.583612   \n",
       "5  132539.0 2025-03-10 05:00:00     0.0 -0.950365 -0.231946 -0.583612   \n",
       "6  132539.0 2025-03-10 06:00:00     0.0 -0.950365 -0.231946 -0.583612   \n",
       "7  132539.0 2025-03-10 07:00:00     0.0 -0.950365 -0.231946 -0.583612   \n",
       "8  132539.0 2025-03-10 08:00:00     0.0 -0.950365 -0.231946 -0.583612   \n",
       "9  132539.0 2025-03-10 09:00:00     0.0 -0.950365 -0.231946 -0.583612   \n",
       "\n",
       "    Albumin  Cholesterol   DiasABP      HCO3  ...     Urine       WBC     pH  \\\n",
       "0  1.452191    -0.133234 -0.810049 -0.037519  ...  0.923077  0.318841 -0.250   \n",
       "1  0.171208    -0.693421  0.634509 -2.669841  ...  3.076923  0.608696 -0.625   \n",
       "2  1.025197     0.856429  0.937401 -0.256879  ... -0.384615  0.434783  0.000   \n",
       "3 -0.398117     2.761064  0.587911 -0.037519  ...  0.692308 -0.594203  0.625   \n",
       "4 -0.540449    -0.002524  0.937401  0.181842  ... -0.153846 -0.028986  0.125   \n",
       "5 -0.113454    -1.365645 -0.320763 -0.914959  ... -0.153846 -0.637681 -0.875   \n",
       "6  1.167528    -0.133234 -0.285814 -1.792400  ...  0.692308  0.884058  0.250   \n",
       "7 -0.682780     1.453962  0.937401 -0.914959  ...  0.692308 -0.623188  0.500   \n",
       "8  1.167528    -0.898823 -0.600355  0.401202  ...  0.307692 -0.173913 -1.250   \n",
       "9  0.171208    -0.394655  1.776177  1.278643  ...  0.000000 -1.333333  0.500   \n",
       "\n",
       "   MechVent  TroponinT       ALP        ALT       AST  Bilirubin  TroponinI  \n",
       "0       0.0   1.314286  0.189655  -0.307692  0.037037   1.166667   0.857143  \n",
       "1       0.0  14.571429 -0.500000   1.557692 -0.240741   0.416667  -0.214286  \n",
       "2       0.0   0.542857  2.120690  -0.461538  1.777778   0.083333  -0.178571  \n",
       "3       0.0   2.942857  0.534483  51.769231 -0.259259  22.750000   0.357143  \n",
       "4       0.0   0.857143 -0.224138  -0.096154 -0.018519   1.416667   0.785714  \n",
       "5       0.0  -0.028571  2.189655  -0.403846 -0.240741  -0.583333   0.071429  \n",
       "6       0.0  -0.085714 -0.189655  -0.057692 -0.314815   0.750000   1.857143  \n",
       "7       0.0  -0.228571 -0.500000  -0.173077  0.074074  -0.166667   1.035714  \n",
       "8       0.0   0.371429 -0.482759   3.538462 -0.203704  -0.166667   0.392857  \n",
       "9       0.0  10.285714  0.068966  -0.461538 -0.111111  30.666667  -0.250000  \n",
       "\n",
       "[10 rows x 43 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data from Parquet files\n",
    "sets_dict = {}\n",
    "sets = [\"a\", \"b\", \"c\"]\n",
    "\n",
    "for set_name in sets:\n",
    "    directory = PROCESSED_DATA_DIR / f\"set_{set_name}_final.parquet\"\n",
    "    temp_set = pd.read_parquet(directory)\n",
    "    sets_dict[f\"set_{set_name}\"] = temp_set\n",
    "\n",
    "# Assure the loading was correct\n",
    "print(sets_dict[\"set_a\"].shape)\n",
    "sets_dict[\"set_a\"].head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ICU TYpe da cavare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RecordID             0\n",
      "In-hospital_death    0\n",
      "dtype: int64\n",
      "RecordID             0\n",
      "In-hospital_death    0\n",
      "dtype: int64\n",
      "RecordID             0\n",
      "In-hospital_death    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define file names\n",
    "file_names = [\"Outcomes-a.txt\", \"Outcomes-b.txt\", \"Outcomes-c.txt\"]\n",
    "\n",
    "# Directory path\n",
    "base_path = PROJ_ROOT / \"data\" / \"data_1\" / \"predicting-mortality-of-icu-patients-the-physionet-computing-in-cardiology-challenge-2012-1.0.0\"\n",
    "\n",
    "# Read files into DataFrames containing all variables\n",
    "outcomes_a, outcomes_b, outcomes_c = [pd.read_csv(base_path / name) for name in file_names]\n",
    "\n",
    "# Extract only the \"RecordID\" and \"In-hospital_death\" column into separate DataFrames\n",
    "death_a, death_b, death_c = [df[[\"RecordID\", \"In-hospital_death\"]] for df in [outcomes_a, outcomes_b, outcomes_c]]\n",
    "death_a.head()\n",
    "\n",
    "#CHECK for missing values in the outcome data\n",
    "print(death_a.isnull().sum())\n",
    "print(death_b.isnull().sum())\n",
    "print(death_c.isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Value counts for death_a:\n",
      "\n",
      "In-hospital_death\n",
      "0    3446\n",
      "1     554\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Contains only 0 and 1: True\n",
      "\n",
      "Value counts for death_b:\n",
      "\n",
      "In-hospital_death\n",
      "0    3432\n",
      "1     568\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Contains only 0 and 1: True\n",
      "\n",
      "Value counts for death_c:\n",
      "\n",
      "In-hospital_death\n",
      "0    3415\n",
      "1     585\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Contains only 0 and 1: True\n"
     ]
    }
   ],
   "source": [
    "# Check if each \"In-hospital_death\" column contains only 0 and 1\n",
    "for name, df in zip([\"a\", \"b\", \"c\"], [death_a, death_b, death_c]):\n",
    "    print(f\"\\nValue counts for death_{name}:\\n\")\n",
    "    print(df[\"In-hospital_death\"].value_counts())\n",
    "    print(\"\\nContains only 0 and 1:\", df[\"In-hospital_death\"].isin([0, 1]).all())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So 1 means he died. We are going to fit a classifier to predict death. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial setup for the classifier to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RecordID', 'Time', 'Gender', 'Height', 'Weight', 'Age', 'Albumin',\n",
       "       'Cholesterol', 'DiasABP', 'HCO3', 'HCT', 'HR', 'Mg', 'MAP', 'Na',\n",
       "       'NIDiasABP', 'NIMAP', 'NISysABP', 'SysABP', 'PaCO2', 'PaO2',\n",
       "       'Platelets', 'RespRate', 'Temp', 'BUN', 'Creatinine', 'FiO2', 'GCS',\n",
       "       'Glucose', 'K', 'Lactate', 'SaO2', 'Urine', 'WBC', 'pH', 'MechVent',\n",
       "       'TroponinT', 'ALP', 'ALT', 'AST', 'Bilirubin', 'TroponinI'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the sets you want to modify\n",
    "sets = [\"set_a\", \"set_b\", \"set_c\"]\n",
    "\n",
    "# Delete the column ICUType from each set\n",
    "for set_name in sets:\n",
    "    sets_dict[set_name].drop(columns=[\"ICUType\"], inplace=True)\n",
    "\n",
    "# Check if the column was deleted by printing all the columns of set_a\n",
    "sets_dict[\"set_a\"].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training, validation and testing sets\n",
    "train_set = sets_dict[\"set_a\"]\n",
    "val_set = sets_dict[\"set_b\"]\n",
    "test_set = sets_dict[\"set_c\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#change class of RecordID to int32\n",
    "train_set[\"RecordID\"] = train_set[\"RecordID\"].astype(\"int32\")\n",
    "val_set[\"RecordID\"] = val_set[\"RecordID\"].astype(\"int32\")\n",
    "test_set[\"RecordID\"] = test_set[\"RecordID\"].astype(\"int32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordID</th>\n",
       "      <th>Time</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Age</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>DiasABP</th>\n",
       "      <th>HCO3</th>\n",
       "      <th>...</th>\n",
       "      <th>WBC</th>\n",
       "      <th>pH</th>\n",
       "      <th>MechVent</th>\n",
       "      <th>TroponinT</th>\n",
       "      <th>ALP</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AST</th>\n",
       "      <th>Bilirubin</th>\n",
       "      <th>TroponinI</th>\n",
       "      <th>In-hospital_death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>132539</td>\n",
       "      <td>2025-03-10 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.950365</td>\n",
       "      <td>-0.231946</td>\n",
       "      <td>-0.583612</td>\n",
       "      <td>1.452191</td>\n",
       "      <td>-0.133234</td>\n",
       "      <td>-0.810049</td>\n",
       "      <td>-0.037519</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318841</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.314286</td>\n",
       "      <td>0.189655</td>\n",
       "      <td>-0.307692</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132539</td>\n",
       "      <td>2025-03-10 01:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.950365</td>\n",
       "      <td>-0.231946</td>\n",
       "      <td>-0.583612</td>\n",
       "      <td>0.171208</td>\n",
       "      <td>-0.693421</td>\n",
       "      <td>0.634509</td>\n",
       "      <td>-2.669841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>-0.625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.571429</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>1.557692</td>\n",
       "      <td>-0.240741</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>-0.214286</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>132539</td>\n",
       "      <td>2025-03-10 02:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.950365</td>\n",
       "      <td>-0.231946</td>\n",
       "      <td>-0.583612</td>\n",
       "      <td>1.025197</td>\n",
       "      <td>0.856429</td>\n",
       "      <td>0.937401</td>\n",
       "      <td>-0.256879</td>\n",
       "      <td>...</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>2.120690</td>\n",
       "      <td>-0.461538</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>-0.178571</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132539</td>\n",
       "      <td>2025-03-10 03:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.950365</td>\n",
       "      <td>-0.231946</td>\n",
       "      <td>-0.583612</td>\n",
       "      <td>-0.398117</td>\n",
       "      <td>2.761064</td>\n",
       "      <td>0.587911</td>\n",
       "      <td>-0.037519</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.594203</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.942857</td>\n",
       "      <td>0.534483</td>\n",
       "      <td>51.769231</td>\n",
       "      <td>-0.259259</td>\n",
       "      <td>22.750000</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132539</td>\n",
       "      <td>2025-03-10 04:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.950365</td>\n",
       "      <td>-0.231946</td>\n",
       "      <td>-0.583612</td>\n",
       "      <td>-0.540449</td>\n",
       "      <td>-0.002524</td>\n",
       "      <td>0.937401</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028986</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>-0.224138</td>\n",
       "      <td>-0.096154</td>\n",
       "      <td>-0.018519</td>\n",
       "      <td>1.416667</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RecordID                Time  Gender    Height    Weight       Age  \\\n",
       "0    132539 2025-03-10 00:00:00     0.0 -0.950365 -0.231946 -0.583612   \n",
       "1    132539 2025-03-10 01:00:00     0.0 -0.950365 -0.231946 -0.583612   \n",
       "2    132539 2025-03-10 02:00:00     0.0 -0.950365 -0.231946 -0.583612   \n",
       "3    132539 2025-03-10 03:00:00     0.0 -0.950365 -0.231946 -0.583612   \n",
       "4    132539 2025-03-10 04:00:00     0.0 -0.950365 -0.231946 -0.583612   \n",
       "\n",
       "    Albumin  Cholesterol   DiasABP      HCO3  ...       WBC     pH  MechVent  \\\n",
       "0  1.452191    -0.133234 -0.810049 -0.037519  ...  0.318841 -0.250       0.0   \n",
       "1  0.171208    -0.693421  0.634509 -2.669841  ...  0.608696 -0.625       0.0   \n",
       "2  1.025197     0.856429  0.937401 -0.256879  ...  0.434783  0.000       0.0   \n",
       "3 -0.398117     2.761064  0.587911 -0.037519  ... -0.594203  0.625       0.0   \n",
       "4 -0.540449    -0.002524  0.937401  0.181842  ... -0.028986  0.125       0.0   \n",
       "\n",
       "   TroponinT       ALP        ALT       AST  Bilirubin  TroponinI  \\\n",
       "0   1.314286  0.189655  -0.307692  0.037037   1.166667   0.857143   \n",
       "1  14.571429 -0.500000   1.557692 -0.240741   0.416667  -0.214286   \n",
       "2   0.542857  2.120690  -0.461538  1.777778   0.083333  -0.178571   \n",
       "3   2.942857  0.534483  51.769231 -0.259259  22.750000   0.357143   \n",
       "4   0.857143 -0.224138  -0.096154 -0.018519   1.416667   0.785714   \n",
       "\n",
       "   In-hospital_death  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the training, validation and testing sets with the corresponding death DataFrames\n",
    "train_set = train_set.merge(death_a, on=\"RecordID\")\n",
    "val_set = val_set.merge(death_b, on=\"RecordID\") \n",
    "test_set = test_set.merge(death_c, on=\"RecordID\")\n",
    "\n",
    "# Check if the merge was successful by printing the first 5 rows of the training set\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Height</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>ALP</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AST</th>\n",
       "      <th>Bilirubin</th>\n",
       "      <th>BUN</th>\n",
       "      <th>...</th>\n",
       "      <th>RespRate</th>\n",
       "      <th>SaO2</th>\n",
       "      <th>SysABP</th>\n",
       "      <th>Temp</th>\n",
       "      <th>TroponinI</th>\n",
       "      <th>TroponinT</th>\n",
       "      <th>Urine</th>\n",
       "      <th>WBC</th>\n",
       "      <th>Weight</th>\n",
       "      <th>In-hospital_death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>132539</td>\n",
       "      <td>-0.583612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.950365</td>\n",
       "      <td>-1.252106</td>\n",
       "      <td>-0.586207</td>\n",
       "      <td>-0.461538</td>\n",
       "      <td>1.259259</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>-0.588235</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.322617</td>\n",
       "      <td>-0.979592</td>\n",
       "      <td>-0.152341</td>\n",
       "      <td>2.504504</td>\n",
       "      <td>9.714286</td>\n",
       "      <td>16.8</td>\n",
       "      <td>35.615385</td>\n",
       "      <td>-0.304348</td>\n",
       "      <td>-0.231946</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132540</td>\n",
       "      <td>0.669324</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.618599</td>\n",
       "      <td>-1.252106</td>\n",
       "      <td>-0.586207</td>\n",
       "      <td>-0.461538</td>\n",
       "      <td>1.259259</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003777</td>\n",
       "      <td>-1.285714</td>\n",
       "      <td>-0.008614</td>\n",
       "      <td>2.504504</td>\n",
       "      <td>9.714286</td>\n",
       "      <td>16.8</td>\n",
       "      <td>26.985897</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>-0.234578</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>132541</td>\n",
       "      <td>-1.153129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.429179</td>\n",
       "      <td>-1.109774</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>2.462963</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>-0.882353</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003777</td>\n",
       "      <td>-2.142857</td>\n",
       "      <td>-0.033771</td>\n",
       "      <td>2.504504</td>\n",
       "      <td>9.714286</td>\n",
       "      <td>16.8</td>\n",
       "      <td>21.969231</td>\n",
       "      <td>-0.768116</td>\n",
       "      <td>-1.081104</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132543</td>\n",
       "      <td>0.213711</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.159248</td>\n",
       "      <td>1.879185</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.403846</td>\n",
       "      <td>-0.296296</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.470588</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.712056</td>\n",
       "      <td>-0.979592</td>\n",
       "      <td>-0.152341</td>\n",
       "      <td>2.504504</td>\n",
       "      <td>9.714286</td>\n",
       "      <td>16.8</td>\n",
       "      <td>135.250000</td>\n",
       "      <td>-0.521739</td>\n",
       "      <td>0.142631</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132545</td>\n",
       "      <td>1.352744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.252047</td>\n",
       "      <td>0.313540</td>\n",
       "      <td>-0.586207</td>\n",
       "      <td>-0.461538</td>\n",
       "      <td>1.259259</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048940</td>\n",
       "      <td>-0.979592</td>\n",
       "      <td>-0.152341</td>\n",
       "      <td>2.504504</td>\n",
       "      <td>9.714286</td>\n",
       "      <td>16.8</td>\n",
       "      <td>-4.300000</td>\n",
       "      <td>-0.971014</td>\n",
       "      <td>-0.812672</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RecordID       Age  Gender    Height   Albumin       ALP       ALT  \\\n",
       "0    132539 -0.583612     0.0 -0.950365 -1.252106 -0.586207 -0.461538   \n",
       "1    132540  0.669324     1.0  0.618599 -1.252106 -0.586207 -0.461538   \n",
       "2    132541 -1.153129     0.0 -0.429179 -1.109774  0.500000  0.807692   \n",
       "3    132543  0.213711     1.0  1.159248  1.879185  0.500000 -0.403846   \n",
       "4    132545  1.352744     0.0 -1.252047  0.313540 -0.586207 -0.461538   \n",
       "\n",
       "        AST  Bilirubin       BUN  ...  RespRate      SaO2    SysABP      Temp  \\\n",
       "0  1.259259  -0.250000 -0.588235  ... -0.322617 -0.979592 -0.152341  2.504504   \n",
       "1  1.259259  -0.250000  0.176471  ... -0.003777 -1.285714 -0.008614  2.504504   \n",
       "2  2.462963   1.666667 -0.882353  ... -0.003777 -2.142857 -0.033771  2.504504   \n",
       "3 -0.296296  -0.500000 -0.470588  ... -0.712056 -0.979592 -0.152341  2.504504   \n",
       "4  1.259259  -0.250000  0.411765  ... -0.048940 -0.979592 -0.152341  2.504504   \n",
       "\n",
       "   TroponinI  TroponinT       Urine       WBC    Weight  In-hospital_death  \n",
       "0   9.714286       16.8   35.615385 -0.304348 -0.231946                  0  \n",
       "1   9.714286       16.8   26.985897  0.260870 -0.234578                  0  \n",
       "2   9.714286       16.8   21.969231 -0.768116 -1.081104                  0  \n",
       "3   9.714286       16.8  135.250000 -0.521739  0.142631                  0  \n",
       "4   9.714286       16.8   -4.300000 -0.971014 -0.812672                  0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define aggregation rules\n",
    "aggregation_rules = {\n",
    "    \"Age\": \"last\",\n",
    "    \"Gender\": \"last\",\n",
    "    \"Height\": \"last\",\n",
    "    \"Albumin\": \"last\",\n",
    "    \"ALP\": \"last\",\n",
    "    \"ALT\": \"last\",\n",
    "    \"AST\": \"last\",\n",
    "    \"Bilirubin\": \"last\",\n",
    "    \"BUN\": \"last\",\n",
    "    \"Cholesterol\": \"last\",\n",
    "    \"Creatinine\": \"last\",\n",
    "    \"DiasABP\": \"mean\",\n",
    "    \"FiO2\": \"mean\",\n",
    "    \"GCS\": \"min\",\n",
    "    \"Glucose\": \"mean\",\n",
    "    \"HCO3\": \"last\",\n",
    "    \"HCT\": \"last\",\n",
    "    \"HR\": \"mean\",\n",
    "    \"K\": \"last\",\n",
    "    \"Lactate\": \"max\",\n",
    "    \"Mg\": \"last\",\n",
    "    \"MAP\": \"mean\",\n",
    "    \"MechVent\": \"last\",\n",
    "    \"Na\": \"last\",\n",
    "    \"NIDiasABP\": \"mean\",\n",
    "    \"NIMAP\": \"mean\",\n",
    "    \"NISysABP\": \"mean\",\n",
    "    \"PaCO2\": \"last\",\n",
    "    \"PaO2\": \"mean\",\n",
    "    \"pH\": \"last\",\n",
    "    \"Platelets\": \"last\",\n",
    "    \"RespRate\": \"mean\",\n",
    "    \"SaO2\": \"mean\",\n",
    "    \"SysABP\": \"mean\",\n",
    "    \"Temp\": \"max\",\n",
    "    \"TroponinI\": \"max\",\n",
    "    \"TroponinT\": \"max\",\n",
    "    \"Urine\": \"sum\",\n",
    "    \"WBC\": \"last\",\n",
    "    \"Weight\": \"last\",\n",
    "    \"In-hospital_death\": \"max\"  # If any 1 exists for a patient, return 1\n",
    "}\n",
    "\n",
    "# Perform aggregation\n",
    "train_aggregated = train_set.groupby(\"RecordID\").agg(aggregation_rules).reset_index()\n",
    "val_aggregated = val_set.groupby(\"RecordID\").agg(aggregation_rules).reset_index()\n",
    "test_aggregated = test_set.groupby(\"RecordID\").agg(aggregation_rules).reset_index()\n",
    "\n",
    "\n",
    "# Display the processed dataset\n",
    "train_aggregated.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1 - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 40) (4000,)\n"
     ]
    }
   ],
   "source": [
    "# Separate Predictors (X) and Target (y)\n",
    "X_train = train_aggregated.drop(columns=[\"RecordID\", \"In-hospital_death\"])\n",
    "y_train = train_aggregated[\"In-hospital_death\"]\n",
    "\n",
    "X_val = val_aggregated.drop(columns=[\"RecordID\", \"In-hospital_death\"])\n",
    "y_val = val_aggregated[\"In-hospital_death\"]\n",
    "\n",
    "X_test = test_aggregated.drop(columns=[\"RecordID\", \"In-hospital_death\"])\n",
    "y_test = test_aggregated[\"In-hospital_death\"]\n",
    "\n",
    "# Visualize the shape of the datasets\n",
    "print(X_train.shape, y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation ROC AUC: 0.786, AUPRC: 0.408\n",
      "Test ROC AUC: 0.758, AUPRC: 0.368\n"
     ]
    }
   ],
   "source": [
    "#El bondiano fa una logistica daje\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "# --- Assume these DataFrames are already defined ---\n",
    "# train_df = pd.read_csv(\"train.csv\")\n",
    "# valid_df = pd.read_csv(\"validate.csv\")\n",
    "# test_df  = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Separate features and target for each set.\n",
    "# Adjust the column name \"target\" to your actual target column name.\n",
    "\n",
    "# Create and train the Logistic Regression classifier.\n",
    "clf = LogisticRegression(random_state=SEED, max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Optionally, evaluate on the validation set.\n",
    "y_valid_proba = clf.predict_proba(X_val)[:, 1]  # probability for the positive class\n",
    "roc_auc_valid = roc_auc_score(y_val, y_valid_proba)\n",
    "auprc_valid = average_precision_score(y_val, y_valid_proba)\n",
    "print(f\"Validation ROC AUC: {roc_auc_valid:.3f}, AUPRC: {auprc_valid:.3f}\")\n",
    "\n",
    "# Evaluate on the test set.\n",
    "y_test_proba = clf.predict_proba(X_test)[:, 1]\n",
    "roc_auc_test = roc_auc_score(y_test, y_test_proba)\n",
    "auprc_test = average_precision_score(y_test, y_test_proba)\n",
    "print(f\"Test ROC AUC: {roc_auc_test:.3f}, AUPRC: {auprc_test:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2 - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation ROC AUC: 0.781, AUPRC: 0.421\n",
      "Test ROC AUC: 0.739, AUPRC: 0.392\n"
     ]
    }
   ],
   "source": [
    "# Use Random Forest to predict the target\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create and train the Random Forest classifier.\n",
    "clf = RandomForestClassifier(random_state=SEED)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Optionally, evaluate on the validation set.\n",
    "y_valid_proba = clf.predict_proba(X_val)[:, 1]  # probability for the positive class\n",
    "roc_auc_valid = roc_auc_score(y_val, y_valid_proba)\n",
    "auprc_valid = average_precision_score(y_val, y_valid_proba)\n",
    "print(f\"Validation ROC AUC: {roc_auc_valid:.3f}, AUPRC: {auprc_valid:.3f}\")\n",
    "\n",
    "# Evaluate on the test set.\n",
    "y_test_proba = clf.predict_proba(X_test)[:, 1]\n",
    "roc_auc_test = roc_auc_score(y_test, y_test_proba)\n",
    "auprc_test = average_precision_score(y_test, y_test_proba)\n",
    "print(f\"Test ROC AUC: {roc_auc_test:.3f}, AUPRC: {auprc_test:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A little comment on the results:\n",
    "\n",
    "AUC Score is pretty good. However, AUPRC is not that high. A problem that could arise is class imbalance. In fact, we have two classes, where the size of the 0 class is 6x the size of the 1 class. However, all three sets share the same problem, so it should not be a big problem. Another possible implementation could be using a dimensionality reduction technique, or some feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2.1 - Feature Engineering\n",
    "\n",
    "We could use solutions such as *_Feature Lagging_*, *_Temporal Differences_* or *_Rolling Statistics_* to better capture the time-series trends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 2 - Signal processing-based features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use tsfresh to extract a large amount of features. \n",
    "\n",
    "*Note* the use of MinimalFCParameters, to reduce the number of variables inspected (and so the high computational cost) \n",
    "\n",
    "Also tryied to substitute w/ EfficientFCParameters but still the run time is too much.\n",
    "\n",
    "Maybe we should try to use the student cluster but we'll see\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 20/20 [00:09<00:00,  2.12it/s]\n",
      "Feature Extraction: 100%|██████████| 20/20 [00:09<00:00,  2.13it/s]\n",
      "Feature Extraction: 100%|██████████| 20/20 [00:09<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set relevant features: (4000, 203)\n",
      "Validation set relevant features: (4000, 203)\n",
      "Test set relevant features: (4000, 203)\n"
     ]
    }
   ],
   "source": [
    "from tsfresh import extract_features, select_features\n",
    "from tsfresh.feature_extraction.settings import MinimalFCParameters\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "\n",
    "# Define the column names\n",
    "id_column = \"RecordID\"\n",
    "time_column = \"Time\"\n",
    "target_column = \"In-hospital_death\"\n",
    "\n",
    "# Step 1: Extract all features from train_set using MinimalFCParameters\n",
    "X_train_extracted = extract_features(\n",
    "    train_set.drop(columns=[target_column]),\n",
    "    column_id=id_column,\n",
    "    column_sort=time_column,\n",
    "    default_fc_parameters=MinimalFCParameters()  # Use minimal features\n",
    ")\n",
    "\n",
    "# Impute missing values (tsfresh requires no NaNs)\n",
    "X_train_extracted = impute(X_train_extracted)\n",
    "\n",
    "# Step 2: Select relevant features based on the target variable\n",
    "y_train = train_set.groupby(id_column)[target_column].max()\n",
    "X_train_relevant = select_features(X_train_extracted, y_train)\n",
    "\n",
    "# Step 3: Store the relevant feature names\n",
    "relevant_feature_names = X_train_relevant.columns\n",
    "\n",
    "# Step 4: Extract the same features for val_set\n",
    "X_val_extracted = extract_features(\n",
    "    val_set.drop(columns=[target_column]),\n",
    "    column_id=id_column,\n",
    "    column_sort=time_column,\n",
    "    default_fc_parameters=MinimalFCParameters()  # Use the same settings\n",
    ")\n",
    "X_val_extracted = impute(X_val_extracted)  # Impute missing values\n",
    "X_val_relevant = X_val_extracted[relevant_feature_names]  # Keep only relevant features\n",
    "\n",
    "# Step 5: Extract the same features for test_set\n",
    "X_test_extracted = extract_features(\n",
    "    test_set.drop(columns=[target_column]),\n",
    "    column_id=id_column,\n",
    "    column_sort=time_column,\n",
    "    default_fc_parameters=MinimalFCParameters()  # Use the same settings\n",
    ")\n",
    "X_test_extracted = impute(X_test_extracted)  # Impute missing values\n",
    "X_test_relevant = X_test_extracted[relevant_feature_names]  # Keep only relevant features\n",
    "\n",
    "# Now X_train_relevant, X_val_relevant, and X_test_relevant have the same features\n",
    "print(\"Train set relevant features:\", X_train_relevant.shape)\n",
    "print(\"Validation set relevant features:\", X_val_relevant.shape)\n",
    "print(\"Test set relevant features:\", X_test_relevant.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For train_set\n",
    "y_train = train_set.groupby(id_column)[target_column].max()\n",
    "\n",
    "# For val_set\n",
    "y_val = val_set.groupby(id_column)[target_column].max()\n",
    "\n",
    "# For test_set\n",
    "y_test = test_set.groupby(id_column)[target_column].max()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation ROC AUC: 0.804, AUPRC: 0.410\n",
      "Test ROC AUC: 0.770, AUPRC: 0.343\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# --- Scale the features ---\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the training data and transform\n",
    "X_train_scaled = scaler.fit_transform(X_train_relevant)\n",
    "\n",
    "# Transform the validation and test sets using the same scaler\n",
    "X_val_scaled = scaler.transform(X_val_relevant)\n",
    "X_test_scaled = scaler.transform(X_test_relevant)\n",
    "\n",
    "# --- Create and train the Logistic Regression classifier ---\n",
    "clf = LogisticRegression(random_state=42, max_iter=5000)  # Increase iterations to 5000\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# --- Evaluate on the validation set ---\n",
    "y_val_proba = clf.predict_proba(X_val_scaled)[:, 1]  # Probability for the positive class\n",
    "roc_auc_val = roc_auc_score(y_val, y_val_proba)\n",
    "auprc_val = average_precision_score(y_val, y_val_proba)\n",
    "print(f\"Validation ROC AUC: {roc_auc_val:.3f}, AUPRC: {auprc_val:.3f}\")\n",
    "\n",
    "# --- Evaluate on the test set ---\n",
    "y_test_proba = clf.predict_proba(X_test_scaled)[:, 1]\n",
    "roc_auc_test = roc_auc_score(y_test, y_test_proba)\n",
    "auprc_test = average_precision_score(y_test, y_test_proba)\n",
    "print(f\"Test ROC AUC: {roc_auc_test:.3f}, AUPRC: {auprc_test:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there is a total of 215 features exctracted, we'll try with some regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation with Logistic Regression (l2-reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Best regularization parameter (C): 0.01\n",
      "Validation ROC AUC: 0.830, AUPRC: 0.450\n",
      "Test ROC AUC: 0.803, AUPRC: 0.391\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# --- Scale the features ---\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the training data and transform\n",
    "X_train_scaled = scaler.fit_transform(X_train_relevant)\n",
    "\n",
    "# Transform the validation and test sets using the same scaler\n",
    "X_val_scaled = scaler.transform(X_val_relevant)\n",
    "X_test_scaled = scaler.transform(X_test_relevant)\n",
    "\n",
    "# --- Define the Logistic Regression model ---\n",
    "# Use L2 regularization (default) and set up the solver\n",
    "log_reg = LogisticRegression(random_state=42, max_iter=5000, penalty='l2', solver='liblinear')\n",
    "\n",
    "# --- Set up the grid search for hyperparameter tuning ---\n",
    "# Define the range of C values to test\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]}\n",
    "\n",
    "# Use ROC AUC as the scoring metric for grid search\n",
    "grid_search = GridSearchCV(estimator=log_reg, param_grid=param_grid, scoring='roc_auc', cv=5, verbose=1)\n",
    "\n",
    "# --- Perform grid search on the training data ---\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# --- Get the best model and its parameters ---\n",
    "best_clf = grid_search.best_estimator_\n",
    "best_C = grid_search.best_params_['C']\n",
    "print(f\"Best regularization parameter (C): {best_C}\")\n",
    "\n",
    "# --- Evaluate on the validation set using the best model ---\n",
    "y_val_proba = best_clf.predict_proba(X_val_scaled)[:, 1]  # Probability for the positive class\n",
    "roc_auc_val = roc_auc_score(y_val, y_val_proba)\n",
    "auprc_val = average_precision_score(y_val, y_val_proba)\n",
    "print(f\"Validation ROC AUC: {roc_auc_val:.3f}, AUPRC: {auprc_val:.3f}\")\n",
    "\n",
    "# --- Evaluate on the test set using the best model ---\n",
    "y_test_proba = best_clf.predict_proba(X_test_scaled)[:, 1]\n",
    "roc_auc_test = roc_auc_score(y_test, y_test_proba)\n",
    "auprc_test = average_precision_score(y_test, y_test_proba)\n",
    "print(f\"Test ROC AUC: {roc_auc_test:.3f}, AUPRC: {auprc_test:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation with Logistic Regression (l1- reg)\n",
    "\n",
    "Since Lasso convergence is slower, we improved it by using the saga solver, increasing the iterations, adjusting the tolerance and also doing the grid search with every processor (n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Best regularization parameter (C): 0.1\n",
      "Validation ROC AUC: 0.832, AUPRC: 0.457\n",
      "Test ROC AUC: 0.811, AUPRC: 0.403\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# --- Scale the features ---\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_relevant)\n",
    "X_val_scaled = scaler.transform(X_val_relevant)\n",
    "X_test_scaled = scaler.transform(X_test_relevant)\n",
    "\n",
    "# --- Define the Logistic Regression model with L1 regularization ---\n",
    "log_reg = LogisticRegression(\n",
    "    penalty='l1', \n",
    "    solver='saga', \n",
    "    max_iter=5000,  # Increase max_iter\n",
    "    tol=1e-3,       # Adjust tolerance\n",
    "    warm_start=True, # Enable warm start\n",
    "    random_state=42\n",
    ")\n",
    "# --- Set up the grid search for hyperparameter tuning ---\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]}\n",
    "grid_search = GridSearchCV(estimator=log_reg, param_grid=param_grid, scoring='roc_auc', cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "# --- Perform grid search on the training data ---\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# --- Get the best model and its parameters ---\n",
    "best_clf = grid_search.best_estimator_\n",
    "best_C = grid_search.best_params_['C']\n",
    "print(f\"Best regularization parameter (C): {best_C}\")\n",
    "\n",
    "# --- Evaluate on the validation set using the best model ---\n",
    "y_val_proba = best_clf.predict_proba(X_val_scaled)[:, 1]\n",
    "roc_auc_val = roc_auc_score(y_val, y_val_proba)\n",
    "auprc_val = average_precision_score(y_val, y_val_proba)\n",
    "print(f\"Validation ROC AUC: {roc_auc_val:.3f}, AUPRC: {auprc_val:.3f}\")\n",
    "\n",
    "# --- Evaluate on the test set using the best model ---\n",
    "y_test_proba = best_clf.predict_proba(X_test_scaled)[:, 1]\n",
    "roc_auc_test = roc_auc_score(y_test, y_test_proba)\n",
    "auprc_test = average_precision_score(y_test, y_test_proba)\n",
    "print(f\"Test ROC AUC: {roc_auc_test:.3f}, AUPRC: {auprc_test:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best hyperparameters: {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 20}\n",
      "Validation ROC AUC: 0.808, AUPRC: 0.435\n",
      "Test ROC AUC: 0.765, AUPRC: 0.423\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import numpy as np\n",
    "\n",
    "# --- Define the Random Forest Classifier ---\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)  # Use all CPU cores\n",
    "\n",
    "# --- Set up the randomized search for hyperparameter tuning ---\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200],  # Number of trees\n",
    "    'max_depth': [10, 20],       # Maximum depth of each tree\n",
    "    'min_samples_split': [2, 5], # Minimum samples to split a node\n",
    "    'min_samples_leaf': [1, 2],  # Minimum samples at each leaf node\n",
    "    'max_features': ['sqrt', 'log2']  # Number of features to consider at each split\n",
    "}\n",
    "\n",
    "# Use RandomizedSearchCV with a fixed number of iterations\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,  # Number of hyperparameter combinations to try\n",
    "    scoring='roc_auc',\n",
    "    cv=5,\n",
    "    n_jobs=-1,  # Use all CPU cores\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# --- Perform randomized search on the training data ---\n",
    "random_search.fit(X_train_relevant, y_train)\n",
    "\n",
    "# --- Get the best model and its parameters ---\n",
    "best_clf = random_search.best_estimator_\n",
    "best_params = random_search.best_params_\n",
    "print(f\"Best hyperparameters: {best_params}\")\n",
    "\n",
    "# --- Evaluate on the validation set using the best model ---\n",
    "y_val_proba = best_clf.predict_proba(X_val_relevant)[:, 1]  # Probability for the positive class\n",
    "roc_auc_val = roc_auc_score(y_val, y_val_proba)\n",
    "auprc_val = average_precision_score(y_val, y_val_proba)\n",
    "print(f\"Validation ROC AUC: {roc_auc_val:.3f}, AUPRC: {auprc_val:.3f}\")\n",
    "\n",
    "# --- Evaluate on the test set using the best model ---\n",
    "y_test_proba = best_clf.predict_proba(X_test_relevant)[:, 1]\n",
    "roc_auc_test = roc_auc_score(y_test, y_test_proba)\n",
    "auprc_test = average_precision_score(y_test, y_test_proba)\n",
    "print(f\"Test ROC AUC: {roc_auc_test:.3f}, AUPRC: {auprc_test:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without hyperparameter tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation ROC AUC: 0.793, AUPRC: 0.421\n",
      "Test ROC AUC: 0.757, AUPRC: 0.398\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "# --- Definisci il modello Random Forest con parametri predefiniti ---\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)  # Usa tutti i core della CPU\n",
    "\n",
    "# --- Addestra il modello sui dati di training ---\n",
    "rf.fit(X_train_relevant, y_train)\n",
    "\n",
    "# --- Valuta sul validation set ---\n",
    "y_val_proba = rf.predict_proba(X_val_relevant)[:, 1]  # Probabilità per la classe positiva\n",
    "roc_auc_val = roc_auc_score(y_val, y_val_proba)\n",
    "auprc_val = average_precision_score(y_val, y_val_proba)\n",
    "print(f\"Validation ROC AUC: {roc_auc_val:.3f}, AUPRC: {auprc_val:.3f}\")\n",
    "\n",
    "# --- Valuta sul test set ---\n",
    "y_test_proba = rf.predict_proba(X_test_relevant)[:, 1]\n",
    "roc_auc_test = roc_auc_score(y_test, y_test_proba)\n",
    "auprc_test = average_precision_score(y_test, y_test_proba)\n",
    "print(f\"Test ROC AUC: {roc_auc_test:.3f}, AUPRC: {auprc_test:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TUM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
