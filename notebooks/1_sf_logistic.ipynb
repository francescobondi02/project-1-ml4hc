{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2.1 Classic Machine Learning Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-21 23:49:57.597\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproject_1.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mPROJ_ROOT path is: C:\\Users\\Menelao\\Desktop\\Health_care\\project-1-ml4hc\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from project_1.config import PROCESSED_DATA_DIR, PROJ_ROOT\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(183416, 43)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordID</th>\n",
       "      <th>Time</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Age</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>DiasABP</th>\n",
       "      <th>HCO3</th>\n",
       "      <th>...</th>\n",
       "      <th>ICUType</th>\n",
       "      <th>K</th>\n",
       "      <th>Lactate</th>\n",
       "      <th>MechVent</th>\n",
       "      <th>Urine</th>\n",
       "      <th>WBC</th>\n",
       "      <th>pH</th>\n",
       "      <th>SaO2</th>\n",
       "      <th>TroponinT</th>\n",
       "      <th>TroponinI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>132539.0</td>\n",
       "      <td>2025-03-10 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.953317</td>\n",
       "      <td>0.283445</td>\n",
       "      <td>-0.596332</td>\n",
       "      <td>1.004449</td>\n",
       "      <td>-0.069047</td>\n",
       "      <td>-0.739159</td>\n",
       "      <td>-1.269243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.625</td>\n",
       "      <td>-0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.96</td>\n",
       "      <td>0.271429</td>\n",
       "      <td>-0.750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>-0.224490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132539.0</td>\n",
       "      <td>2025-03-10 01:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.953317</td>\n",
       "      <td>0.283445</td>\n",
       "      <td>-0.596332</td>\n",
       "      <td>-0.232975</td>\n",
       "      <td>1.997003</td>\n",
       "      <td>0.232700</td>\n",
       "      <td>-2.924060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.375</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>-15.5</td>\n",
       "      <td>-0.177778</td>\n",
       "      <td>0.408163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>132539.0</td>\n",
       "      <td>2025-03-10 02:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.953317</td>\n",
       "      <td>0.283445</td>\n",
       "      <td>-0.596332</td>\n",
       "      <td>-1.132919</td>\n",
       "      <td>2.628972</td>\n",
       "      <td>2.440210</td>\n",
       "      <td>0.385573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.625</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>2.185714</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132539.0</td>\n",
       "      <td>2025-03-10 03:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.953317</td>\n",
       "      <td>0.283445</td>\n",
       "      <td>-0.596332</td>\n",
       "      <td>-0.120482</td>\n",
       "      <td>-1.721888</td>\n",
       "      <td>1.169851</td>\n",
       "      <td>-0.441835</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>2.185714</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>2.040816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132539.0</td>\n",
       "      <td>2025-03-10 04:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.953317</td>\n",
       "      <td>0.283445</td>\n",
       "      <td>-0.596332</td>\n",
       "      <td>-0.120482</td>\n",
       "      <td>1.462261</td>\n",
       "      <td>-0.392067</td>\n",
       "      <td>-2.510356</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.957143</td>\n",
       "      <td>0.375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.795918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>132539.0</td>\n",
       "      <td>2025-03-10 05:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.953317</td>\n",
       "      <td>0.283445</td>\n",
       "      <td>-0.596332</td>\n",
       "      <td>1.341928</td>\n",
       "      <td>1.146276</td>\n",
       "      <td>-0.235875</td>\n",
       "      <td>0.178721</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-2.125</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>1.557143</td>\n",
       "      <td>-0.375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.244444</td>\n",
       "      <td>0.183673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>132539.0</td>\n",
       "      <td>2025-03-10 06:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.953317</td>\n",
       "      <td>0.283445</td>\n",
       "      <td>-0.596332</td>\n",
       "      <td>1.341928</td>\n",
       "      <td>-0.506564</td>\n",
       "      <td>-0.322648</td>\n",
       "      <td>-0.234983</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.557143</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>-0.081633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>132539.0</td>\n",
       "      <td>2025-03-10 08:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.953317</td>\n",
       "      <td>0.283445</td>\n",
       "      <td>-0.596332</td>\n",
       "      <td>-1.357905</td>\n",
       "      <td>-0.117660</td>\n",
       "      <td>-0.010265</td>\n",
       "      <td>1.419833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-0.657143</td>\n",
       "      <td>-0.625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.911111</td>\n",
       "      <td>8.408163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>132539.0</td>\n",
       "      <td>2025-03-10 09:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.953317</td>\n",
       "      <td>0.283445</td>\n",
       "      <td>-0.596332</td>\n",
       "      <td>-1.132919</td>\n",
       "      <td>0.344163</td>\n",
       "      <td>0.232700</td>\n",
       "      <td>-0.028131</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.657143</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.088889</td>\n",
       "      <td>-0.020408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>132539.0</td>\n",
       "      <td>2025-03-10 10:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.953317</td>\n",
       "      <td>0.283445</td>\n",
       "      <td>-0.596332</td>\n",
       "      <td>-1.470399</td>\n",
       "      <td>0.076791</td>\n",
       "      <td>0.302119</td>\n",
       "      <td>0.385573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.375</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>-0.014286</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.555556</td>\n",
       "      <td>0.040816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RecordID                Time  Gender    Height    Weight       Age  \\\n",
       "0  132539.0 2025-03-10 00:00:00     0.0 -0.953317  0.283445 -0.596332   \n",
       "1  132539.0 2025-03-10 01:00:00     0.0 -0.953317  0.283445 -0.596332   \n",
       "2  132539.0 2025-03-10 02:00:00     0.0 -0.953317  0.283445 -0.596332   \n",
       "3  132539.0 2025-03-10 03:00:00     0.0 -0.953317  0.283445 -0.596332   \n",
       "4  132539.0 2025-03-10 04:00:00     0.0 -0.953317  0.283445 -0.596332   \n",
       "5  132539.0 2025-03-10 05:00:00     0.0 -0.953317  0.283445 -0.596332   \n",
       "6  132539.0 2025-03-10 06:00:00     0.0 -0.953317  0.283445 -0.596332   \n",
       "7  132539.0 2025-03-10 08:00:00     0.0 -0.953317  0.283445 -0.596332   \n",
       "8  132539.0 2025-03-10 09:00:00     0.0 -0.953317  0.283445 -0.596332   \n",
       "9  132539.0 2025-03-10 10:00:00     0.0 -0.953317  0.283445 -0.596332   \n",
       "\n",
       "    Albumin  Cholesterol   DiasABP      HCO3  ...  ICUType      K   Lactate  \\\n",
       "0  1.004449    -0.069047 -0.739159 -1.269243  ...      0.5  0.625 -0.583333   \n",
       "1 -0.232975     1.997003  0.232700 -2.924060  ...      0.5  0.375 -0.166667   \n",
       "2 -1.132919     2.628972  2.440210  0.385573  ...      0.5  0.625  2.000000   \n",
       "3 -0.120482    -1.721888  1.169851 -0.441835  ...      0.5 -1.000 -0.416667   \n",
       "4 -0.120482     1.462261 -0.392067 -2.510356  ...      0.5  0.125  0.000000   \n",
       "5  1.341928     1.146276 -0.235875  0.178721  ...      0.5 -2.125  1.666667   \n",
       "6  1.341928    -0.506564 -0.322648 -0.234983  ...      0.5  0.625  0.833333   \n",
       "7 -1.357905    -0.117660 -0.010265  1.419833  ...      0.5 -0.250  0.250000   \n",
       "8 -1.132919     0.344163  0.232700 -0.028131  ...      0.5 -0.250 -0.416667   \n",
       "9 -1.470399     0.076791  0.302119  0.385573  ...      0.5 -0.375  4.000000   \n",
       "\n",
       "   MechVent  Urine       WBC     pH  SaO2  TroponinT  TroponinI  \n",
       "0       0.0   2.96  0.271429 -0.750   1.0   0.933333  -0.224490  \n",
       "1       0.0   3.20  0.000000  0.750 -15.5  -0.177778   0.408163  \n",
       "2       0.0  -0.40  2.185714 -0.250   1.0   0.333333  -0.285714  \n",
       "3       0.0   0.72  2.185714 -0.250   0.5   0.333333   2.040816  \n",
       "4       0.0  -0.16 -0.957143  0.375   1.0   0.200000   0.795918  \n",
       "5       0.0  -0.16  1.557143 -0.375   0.0  -0.244444   0.183673  \n",
       "6       0.0   0.72  1.557143 -0.125   0.0   0.800000  -0.081633  \n",
       "7       0.0   0.32 -0.657143 -0.625   0.0  20.911111   8.408163  \n",
       "8       0.0   0.00 -0.657143 -0.250   0.0  -0.088889  -0.020408  \n",
       "9       0.0   0.16 -0.014286 -1.000   0.0   1.555556   0.040816  \n",
       "\n",
       "[10 rows x 43 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data from Parquet files\n",
    "sets_dict = {}\n",
    "sets = [\"a\", \"b\", \"c\"]\n",
    "\n",
    "for set_name in sets:\n",
    "    directory = PROCESSED_DATA_DIR / f\"set_{set_name}_final.parquet\"\n",
    "    temp_set = pd.read_parquet(directory)\n",
    "    sets_dict[f\"set_{set_name}\"] = temp_set\n",
    "\n",
    "# Assure the loading was correct\n",
    "print(sets_dict[\"set_a\"].shape)\n",
    "sets_dict[\"set_a\"].head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ICU TYpe da cavare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RecordID             0\n",
      "In-hospital_death    0\n",
      "dtype: int64\n",
      "RecordID             0\n",
      "In-hospital_death    0\n",
      "dtype: int64\n",
      "RecordID             0\n",
      "In-hospital_death    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define file names\n",
    "file_names = [\"Outcomes-a.txt\", \"Outcomes-b.txt\", \"Outcomes-c.txt\"]\n",
    "\n",
    "# Directory path\n",
    "base_path = PROJ_ROOT / \"data\" / \"data_1\" / \"predicting-mortality-of-icu-patients-the-physionet-computing-in-cardiology-challenge-2012-1.0.0\"\n",
    "\n",
    "# Read files into DataFrames containing all variables\n",
    "outcomes_a, outcomes_b, outcomes_c = [pd.read_csv(base_path / name) for name in file_names]\n",
    "\n",
    "# Extract only the \"RecordID\" and \"In-hospital_death\" column into separate DataFrames\n",
    "death_a, death_b, death_c = [df[[\"RecordID\", \"In-hospital_death\"]] for df in [outcomes_a, outcomes_b, outcomes_c]]\n",
    "death_a.head()\n",
    "\n",
    "#CHECK for missing values in the outcome data\n",
    "print(death_a.isnull().sum())\n",
    "print(death_b.isnull().sum())\n",
    "print(death_c.isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Value counts for death_a:\n",
      "\n",
      "In-hospital_death\n",
      "0    3446\n",
      "1     554\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Contains only 0 and 1: True\n",
      "\n",
      "Value counts for death_b:\n",
      "\n",
      "In-hospital_death\n",
      "0    3432\n",
      "1     568\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Contains only 0 and 1: True\n",
      "\n",
      "Value counts for death_c:\n",
      "\n",
      "In-hospital_death\n",
      "0    3415\n",
      "1     585\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Contains only 0 and 1: True\n"
     ]
    }
   ],
   "source": [
    "# Check if each \"In-hospital_death\" column contains only 0 and 1\n",
    "for name, df in zip([\"a\", \"b\", \"c\"], [death_a, death_b, death_c]):\n",
    "    print(f\"\\nValue counts for death_{name}:\\n\")\n",
    "    print(df[\"In-hospital_death\"].value_counts())\n",
    "    print(\"\\nContains only 0 and 1:\", df[\"In-hospital_death\"].isin([0, 1]).all())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So 1 means he died. We are going to fit a classifier to predict death. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial setup for the classifier to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RecordID', 'Time', 'Gender', 'Height', 'Weight', 'Age', 'Albumin',\n",
       "       'Cholesterol', 'DiasABP', 'HCO3', 'HCT', 'HR', 'Mg', 'MAP', 'Na',\n",
       "       'NIDiasABP', 'NIMAP', 'NISysABP', 'SysABP', 'PaCO2', 'PaO2',\n",
       "       'Platelets', 'RespRate', 'Temp', 'ALP', 'ALT', 'AST', 'BUN',\n",
       "       'Bilirubin', 'Creatinine', 'FiO2', 'GCS', 'Glucose', 'K', 'Lactate',\n",
       "       'MechVent', 'Urine', 'WBC', 'pH', 'SaO2', 'TroponinT', 'TroponinI'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the sets you want to modify\n",
    "sets = [\"set_a\", \"set_b\", \"set_c\"]\n",
    "\n",
    "# Delete the column ICUType from each set\n",
    "for set_name in sets:\n",
    "    sets_dict[set_name].drop(columns=[\"ICUType\"], inplace=True)\n",
    "\n",
    "# Check if the column was deleted by printing all the columns of set_a\n",
    "sets_dict[\"set_a\"].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training, validation and testing sets\n",
    "train_set = sets_dict[\"set_a\"]\n",
    "val_set = sets_dict[\"set_b\"]\n",
    "test_set = sets_dict[\"set_c\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#change class of RecordID to int32\n",
    "train_set[\"RecordID\"] = train_set[\"RecordID\"].astype(\"int32\")\n",
    "val_set[\"RecordID\"] = val_set[\"RecordID\"].astype(\"int32\")\n",
    "test_set[\"RecordID\"] = test_set[\"RecordID\"].astype(\"int32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordID</th>\n",
       "      <th>Time</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Age</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>DiasABP</th>\n",
       "      <th>HCO3</th>\n",
       "      <th>...</th>\n",
       "      <th>K</th>\n",
       "      <th>Lactate</th>\n",
       "      <th>MechVent</th>\n",
       "      <th>Urine</th>\n",
       "      <th>WBC</th>\n",
       "      <th>pH</th>\n",
       "      <th>SaO2</th>\n",
       "      <th>TroponinT</th>\n",
       "      <th>TroponinI</th>\n",
       "      <th>In-hospital_death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>132539</td>\n",
       "      <td>2025-03-10 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.953317</td>\n",
       "      <td>0.283445</td>\n",
       "      <td>-0.596332</td>\n",
       "      <td>1.004449</td>\n",
       "      <td>-0.069047</td>\n",
       "      <td>-0.739159</td>\n",
       "      <td>-1.269243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.625</td>\n",
       "      <td>-0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.96</td>\n",
       "      <td>0.271429</td>\n",
       "      <td>-0.750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>-0.224490</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132539</td>\n",
       "      <td>2025-03-10 01:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.953317</td>\n",
       "      <td>0.283445</td>\n",
       "      <td>-0.596332</td>\n",
       "      <td>-0.232975</td>\n",
       "      <td>1.997003</td>\n",
       "      <td>0.232700</td>\n",
       "      <td>-2.924060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.375</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>-15.5</td>\n",
       "      <td>-0.177778</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>132539</td>\n",
       "      <td>2025-03-10 02:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.953317</td>\n",
       "      <td>0.283445</td>\n",
       "      <td>-0.596332</td>\n",
       "      <td>-1.132919</td>\n",
       "      <td>2.628972</td>\n",
       "      <td>2.440210</td>\n",
       "      <td>0.385573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.625</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>2.185714</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132539</td>\n",
       "      <td>2025-03-10 03:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.953317</td>\n",
       "      <td>0.283445</td>\n",
       "      <td>-0.596332</td>\n",
       "      <td>-0.120482</td>\n",
       "      <td>-1.721888</td>\n",
       "      <td>1.169851</td>\n",
       "      <td>-0.441835</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>2.185714</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>2.040816</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132539</td>\n",
       "      <td>2025-03-10 04:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.953317</td>\n",
       "      <td>0.283445</td>\n",
       "      <td>-0.596332</td>\n",
       "      <td>-0.120482</td>\n",
       "      <td>1.462261</td>\n",
       "      <td>-0.392067</td>\n",
       "      <td>-2.510356</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.957143</td>\n",
       "      <td>0.375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RecordID                Time  Gender    Height    Weight       Age  \\\n",
       "0    132539 2025-03-10 00:00:00     0.0 -0.953317  0.283445 -0.596332   \n",
       "1    132539 2025-03-10 01:00:00     0.0 -0.953317  0.283445 -0.596332   \n",
       "2    132539 2025-03-10 02:00:00     0.0 -0.953317  0.283445 -0.596332   \n",
       "3    132539 2025-03-10 03:00:00     0.0 -0.953317  0.283445 -0.596332   \n",
       "4    132539 2025-03-10 04:00:00     0.0 -0.953317  0.283445 -0.596332   \n",
       "\n",
       "    Albumin  Cholesterol   DiasABP      HCO3  ...      K   Lactate  MechVent  \\\n",
       "0  1.004449    -0.069047 -0.739159 -1.269243  ...  0.625 -0.583333       0.0   \n",
       "1 -0.232975     1.997003  0.232700 -2.924060  ...  0.375 -0.166667       0.0   \n",
       "2 -1.132919     2.628972  2.440210  0.385573  ...  0.625  2.000000       0.0   \n",
       "3 -0.120482    -1.721888  1.169851 -0.441835  ... -1.000 -0.416667       0.0   \n",
       "4 -0.120482     1.462261 -0.392067 -2.510356  ...  0.125  0.000000       0.0   \n",
       "\n",
       "   Urine       WBC     pH  SaO2  TroponinT  TroponinI  In-hospital_death  \n",
       "0   2.96  0.271429 -0.750   1.0   0.933333  -0.224490                  0  \n",
       "1   3.20  0.000000  0.750 -15.5  -0.177778   0.408163                  0  \n",
       "2  -0.40  2.185714 -0.250   1.0   0.333333  -0.285714                  0  \n",
       "3   0.72  2.185714 -0.250   0.5   0.333333   2.040816                  0  \n",
       "4  -0.16 -0.957143  0.375   1.0   0.200000   0.795918                  0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the training, validation and testing sets with the corresponding death DataFrames\n",
    "train_set = train_set.merge(death_a, on=\"RecordID\")\n",
    "val_set = val_set.merge(death_b, on=\"RecordID\") \n",
    "test_set = test_set.merge(death_c, on=\"RecordID\")\n",
    "\n",
    "# Check if the merge was successful by printing the first 5 rows of the training set\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Height</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>ALP</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AST</th>\n",
       "      <th>Bilirubin</th>\n",
       "      <th>BUN</th>\n",
       "      <th>...</th>\n",
       "      <th>RespRate</th>\n",
       "      <th>SaO2</th>\n",
       "      <th>SysABP</th>\n",
       "      <th>Temp</th>\n",
       "      <th>TroponinI</th>\n",
       "      <th>TroponinT</th>\n",
       "      <th>Urine</th>\n",
       "      <th>WBC</th>\n",
       "      <th>Weight</th>\n",
       "      <th>In-hospital_death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>132539</td>\n",
       "      <td>-0.596332</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.953317</td>\n",
       "      <td>-0.120482</td>\n",
       "      <td>0.372549</td>\n",
       "      <td>-0.263158</td>\n",
       "      <td>0.289474</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.328319</td>\n",
       "      <td>-0.536458</td>\n",
       "      <td>0.158650</td>\n",
       "      <td>1.448365</td>\n",
       "      <td>8.408163</td>\n",
       "      <td>20.911111</td>\n",
       "      <td>38.320000</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>0.283445</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132540</td>\n",
       "      <td>0.667051</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.615786</td>\n",
       "      <td>-0.120482</td>\n",
       "      <td>0.372549</td>\n",
       "      <td>-0.263158</td>\n",
       "      <td>0.289474</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.10</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011361</td>\n",
       "      <td>-0.428571</td>\n",
       "      <td>-0.151136</td>\n",
       "      <td>1.096722</td>\n",
       "      <td>8.408163</td>\n",
       "      <td>20.911111</td>\n",
       "      <td>30.265333</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>-0.232912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>132541</td>\n",
       "      <td>-1.170597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.432085</td>\n",
       "      <td>-1.020426</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>-0.80</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004531</td>\n",
       "      <td>-0.885417</td>\n",
       "      <td>0.175950</td>\n",
       "      <td>2.386078</td>\n",
       "      <td>8.408163</td>\n",
       "      <td>20.911111</td>\n",
       "      <td>24.688000</td>\n",
       "      <td>-0.757143</td>\n",
       "      <td>-1.078178</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132543</td>\n",
       "      <td>0.207639</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.156482</td>\n",
       "      <td>1.341928</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.535088</td>\n",
       "      <td>-0.555556</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.746235</td>\n",
       "      <td>-0.525510</td>\n",
       "      <td>0.173347</td>\n",
       "      <td>0.041795</td>\n",
       "      <td>8.408163</td>\n",
       "      <td>20.911111</td>\n",
       "      <td>141.272000</td>\n",
       "      <td>-0.514286</td>\n",
       "      <td>0.143735</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132545</td>\n",
       "      <td>1.356169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.117689</td>\n",
       "      <td>0.104504</td>\n",
       "      <td>0.372549</td>\n",
       "      <td>-0.263158</td>\n",
       "      <td>0.289474</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.30</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051654</td>\n",
       "      <td>-0.239362</td>\n",
       "      <td>0.154832</td>\n",
       "      <td>0.979508</td>\n",
       "      <td>8.408163</td>\n",
       "      <td>20.911111</td>\n",
       "      <td>-2.032000</td>\n",
       "      <td>-0.957143</td>\n",
       "      <td>-0.835986</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RecordID       Age  Gender    Height   Albumin       ALP       ALT  \\\n",
       "0    132539 -0.596332     0.0 -0.953317 -0.120482  0.372549 -0.263158   \n",
       "1    132540  0.667051     1.0  0.615786 -0.120482  0.372549 -0.263158   \n",
       "2    132541 -1.170597     0.0 -0.432085 -1.020426  0.431373  0.771930   \n",
       "3    132543  0.207639     1.0  1.156482  1.341928  0.431373 -0.333333   \n",
       "4    132545  1.356169     0.0 -1.117689  0.104504  0.372549 -0.263158   \n",
       "\n",
       "        AST  Bilirubin   BUN  ...  RespRate      SaO2    SysABP      Temp  \\\n",
       "0  0.289474   0.222222 -0.55  ... -0.328319 -0.536458  0.158650  1.448365   \n",
       "1  0.289474   0.222222  0.10  ... -0.011361 -0.428571 -0.151136  1.096722   \n",
       "2  0.771930   2.333333 -0.80  ...  0.004531 -0.885417  0.175950  2.386078   \n",
       "3 -0.535088  -0.555556 -0.45  ... -0.746235 -0.525510  0.173347  0.041795   \n",
       "4  0.289474   0.222222  0.30  ... -0.051654 -0.239362  0.154832  0.979508   \n",
       "\n",
       "   TroponinI  TroponinT       Urine       WBC    Weight  In-hospital_death  \n",
       "0   8.408163  20.911111   38.320000 -0.300000  0.283445                  0  \n",
       "1   8.408163  20.911111   30.265333  0.257143 -0.232912                  0  \n",
       "2   8.408163  20.911111   24.688000 -0.757143 -1.078178                  0  \n",
       "3   8.408163  20.911111  141.272000 -0.514286  0.143735                  0  \n",
       "4   8.408163  20.911111   -2.032000 -0.957143 -0.835986                  0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define aggregation rules\n",
    "aggregation_rules = {\n",
    "    \"Age\": \"last\",\n",
    "    \"Gender\": \"last\",\n",
    "    \"Height\": \"last\",\n",
    "    \"Albumin\": \"last\",\n",
    "    \"ALP\": \"last\",\n",
    "    \"ALT\": \"last\",\n",
    "    \"AST\": \"last\",\n",
    "    \"Bilirubin\": \"last\",\n",
    "    \"BUN\": \"last\",\n",
    "    \"Cholesterol\": \"last\",\n",
    "    \"Creatinine\": \"last\",\n",
    "    \"DiasABP\": \"mean\",\n",
    "    \"FiO2\": \"mean\",\n",
    "    \"GCS\": \"min\",\n",
    "    \"Glucose\": \"mean\",\n",
    "    \"HCO3\": \"last\",\n",
    "    \"HCT\": \"last\",\n",
    "    \"HR\": \"mean\",\n",
    "    \"K\": \"last\",\n",
    "    \"Lactate\": \"max\",\n",
    "    \"Mg\": \"last\",\n",
    "    \"MAP\": \"mean\",\n",
    "    \"MechVent\": \"last\",\n",
    "    \"Na\": \"last\",\n",
    "    \"NIDiasABP\": \"mean\",\n",
    "    \"NIMAP\": \"mean\",\n",
    "    \"NISysABP\": \"mean\",\n",
    "    \"PaCO2\": \"last\",\n",
    "    \"PaO2\": \"mean\",\n",
    "    \"pH\": \"last\",\n",
    "    \"Platelets\": \"last\",\n",
    "    \"RespRate\": \"mean\",\n",
    "    \"SaO2\": \"mean\",\n",
    "    \"SysABP\": \"mean\",\n",
    "    \"Temp\": \"max\",\n",
    "    \"TroponinI\": \"max\",\n",
    "    \"TroponinT\": \"max\",\n",
    "    \"Urine\": \"sum\",\n",
    "    \"WBC\": \"last\",\n",
    "    \"Weight\": \"last\",\n",
    "    \"In-hospital_death\": \"max\"  # If any 1 exists for a patient, return 1\n",
    "}\n",
    "\n",
    "# Perform aggregation\n",
    "train_aggregated = train_set.groupby(\"RecordID\").agg(aggregation_rules).reset_index()\n",
    "val_aggregated = val_set.groupby(\"RecordID\").agg(aggregation_rules).reset_index()\n",
    "test_aggregated = test_set.groupby(\"RecordID\").agg(aggregation_rules).reset_index()\n",
    "\n",
    "\n",
    "# Display the processed dataset\n",
    "train_aggregated.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1 - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 40) (4000,)\n"
     ]
    }
   ],
   "source": [
    "# Separate Predictors (X) and Target (y)\n",
    "X_train = train_aggregated.drop(columns=[\"RecordID\", \"In-hospital_death\"])\n",
    "y_train = train_aggregated[\"In-hospital_death\"]\n",
    "\n",
    "X_val = val_aggregated.drop(columns=[\"RecordID\", \"In-hospital_death\"])\n",
    "y_val = val_aggregated[\"In-hospital_death\"]\n",
    "\n",
    "X_test = test_aggregated.drop(columns=[\"RecordID\", \"In-hospital_death\"])\n",
    "y_test = test_aggregated[\"In-hospital_death\"]\n",
    "\n",
    "# Visualize the shape of the datasets\n",
    "print(X_train.shape, y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation ROC AUC: 0.780, AUPRC: 0.397\n",
      "Test ROC AUC: 0.769, AUPRC: 0.386\n"
     ]
    }
   ],
   "source": [
    "#El bondiano fa una logistica daje\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "# --- Assume these DataFrames are already defined ---\n",
    "# train_df = pd.read_csv(\"train.csv\")\n",
    "# valid_df = pd.read_csv(\"validate.csv\")\n",
    "# test_df  = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Separate features and target for each set.\n",
    "# Adjust the column name \"target\" to your actual target column name.\n",
    "\n",
    "# Create and train the Logistic Regression classifier.\n",
    "clf = LogisticRegression(random_state=SEED, max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Optionally, evaluate on the validation set.\n",
    "y_valid_proba = clf.predict_proba(X_val)[:, 1]  # probability for the positive class\n",
    "roc_auc_valid = roc_auc_score(y_val, y_valid_proba)\n",
    "auprc_valid = average_precision_score(y_val, y_valid_proba)\n",
    "print(f\"Validation ROC AUC: {roc_auc_valid:.3f}, AUPRC: {auprc_valid:.3f}\")\n",
    "\n",
    "# Evaluate on the test set.\n",
    "y_test_proba = clf.predict_proba(X_test)[:, 1]\n",
    "roc_auc_test = roc_auc_score(y_test, y_test_proba)\n",
    "auprc_test = average_precision_score(y_test, y_test_proba)\n",
    "print(f\"Test ROC AUC: {roc_auc_test:.3f}, AUPRC: {auprc_test:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2 - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation ROC AUC: 0.779, AUPRC: 0.421\n",
      "Test ROC AUC: 0.790, AUPRC: 0.424\n"
     ]
    }
   ],
   "source": [
    "# Use Random Forest to predict the target\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create and train the Random Forest classifier.\n",
    "clf = RandomForestClassifier(random_state=SEED)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Optionally, evaluate on the validation set.\n",
    "y_valid_proba = clf.predict_proba(X_val)[:, 1]  # probability for the positive class\n",
    "roc_auc_valid = roc_auc_score(y_val, y_valid_proba)\n",
    "auprc_valid = average_precision_score(y_val, y_valid_proba)\n",
    "print(f\"Validation ROC AUC: {roc_auc_valid:.3f}, AUPRC: {auprc_valid:.3f}\")\n",
    "\n",
    "# Evaluate on the test set.\n",
    "y_test_proba = clf.predict_proba(X_test)[:, 1]\n",
    "roc_auc_test = roc_auc_score(y_test, y_test_proba)\n",
    "auprc_test = average_precision_score(y_test, y_test_proba)\n",
    "print(f\"Test ROC AUC: {roc_auc_test:.3f}, AUPRC: {auprc_test:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A little comment on the results:\n",
    "\n",
    "AUC Score is pretty good. However, AUPRC is not that high. A problem that could arise is class imbalance. In fact, we have two classes, where the size of the 0 class is 6x the size of the 1 class. However, all three sets share the same problem, so it should not be a big problem. Another possible implementation could be using a dimensionality reduction technique, or some feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2.1 - Feature Engineering\n",
    "\n",
    "We could use solutions such as *_Feature Lagging_*, *_Temporal Differences_* or *_Rolling Statistics_* to better capture the time-series trends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 2 - Signal processing-based features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use tsfresh to extract a large amount of features. \n",
    "\n",
    "*Note* the use of MinimalFCParameters, to reduce the number of variables inspected (and so the high computational cost) \n",
    "\n",
    "Also tryied to substitute w/ EfficientFCParameters but still the run time is too much.\n",
    "\n",
    "Maybe we should try to use the student cluster but we'll see\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 20/20 [00:35<00:00,  1.75s/it]\n",
      "Feature Extraction: 100%|██████████| 20/20 [00:32<00:00,  1.65s/it]\n",
      "Feature Extraction: 100%|██████████| 20/20 [00:35<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set relevant features: (4000, 215)\n",
      "Validation set relevant features: (4000, 215)\n",
      "Test set relevant features: (4000, 215)\n"
     ]
    }
   ],
   "source": [
    "from tsfresh import extract_features, select_features\n",
    "from tsfresh.feature_extraction.settings import MinimalFCParameters\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "\n",
    "# Define the column names\n",
    "id_column = \"RecordID\"\n",
    "time_column = \"Time\"\n",
    "target_column = \"In-hospital_death\"\n",
    "\n",
    "# Step 1: Extract all features from train_set using MinimalFCParameters\n",
    "X_train_extracted = extract_features(\n",
    "    train_set.drop(columns=[target_column]),\n",
    "    column_id=id_column,\n",
    "    column_sort=time_column,\n",
    "    default_fc_parameters=MinimalFCParameters()  # Use minimal features\n",
    ")\n",
    "\n",
    "# Impute missing values (tsfresh requires no NaNs)\n",
    "X_train_extracted = impute(X_train_extracted)\n",
    "\n",
    "# Step 2: Select relevant features based on the target variable\n",
    "y_train = train_set.groupby(id_column)[target_column].max()\n",
    "X_train_relevant = select_features(X_train_extracted, y_train)\n",
    "\n",
    "# Step 3: Store the relevant feature names\n",
    "relevant_feature_names = X_train_relevant.columns\n",
    "\n",
    "# Step 4: Extract the same features for val_set\n",
    "X_val_extracted = extract_features(\n",
    "    val_set.drop(columns=[target_column]),\n",
    "    column_id=id_column,\n",
    "    column_sort=time_column,\n",
    "    default_fc_parameters=MinimalFCParameters()  # Use the same settings\n",
    ")\n",
    "X_val_extracted = impute(X_val_extracted)  # Impute missing values\n",
    "X_val_relevant = X_val_extracted[relevant_feature_names]  # Keep only relevant features\n",
    "\n",
    "# Step 5: Extract the same features for test_set\n",
    "X_test_extracted = extract_features(\n",
    "    test_set.drop(columns=[target_column]),\n",
    "    column_id=id_column,\n",
    "    column_sort=time_column,\n",
    "    default_fc_parameters=MinimalFCParameters()  # Use the same settings\n",
    ")\n",
    "X_test_extracted = impute(X_test_extracted)  # Impute missing values\n",
    "X_test_relevant = X_test_extracted[relevant_feature_names]  # Keep only relevant features\n",
    "\n",
    "# Now X_train_relevant, X_val_relevant, and X_test_relevant have the same features\n",
    "print(\"Train set relevant features:\", X_train_relevant.shape)\n",
    "print(\"Validation set relevant features:\", X_val_relevant.shape)\n",
    "print(\"Test set relevant features:\", X_test_relevant.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For train_set\n",
    "y_train = train_set.groupby(id_column)[target_column].max()\n",
    "\n",
    "# For val_set\n",
    "y_val = val_set.groupby(id_column)[target_column].max()\n",
    "\n",
    "# For test_set\n",
    "y_test = test_set.groupby(id_column)[target_column].max()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation ROC AUC: 0.821, AUPRC: 0.438\n",
      "Test ROC AUC: 0.817, AUPRC: 0.469\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# --- Scale the features ---\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the training data and transform\n",
    "X_train_scaled = scaler.fit_transform(X_train_relevant)\n",
    "\n",
    "# Transform the validation and test sets using the same scaler\n",
    "X_val_scaled = scaler.transform(X_val_relevant)\n",
    "X_test_scaled = scaler.transform(X_test_relevant)\n",
    "\n",
    "# --- Create and train the Logistic Regression classifier ---\n",
    "clf = LogisticRegression(random_state=42, max_iter=5000)  # Increase iterations to 5000\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# --- Evaluate on the validation set ---\n",
    "y_val_proba = clf.predict_proba(X_val_scaled)[:, 1]  # Probability for the positive class\n",
    "roc_auc_val = roc_auc_score(y_val, y_val_proba)\n",
    "auprc_val = average_precision_score(y_val, y_val_proba)\n",
    "print(f\"Validation ROC AUC: {roc_auc_val:.3f}, AUPRC: {auprc_val:.3f}\")\n",
    "\n",
    "# --- Evaluate on the test set ---\n",
    "y_test_proba = clf.predict_proba(X_test_scaled)[:, 1]\n",
    "roc_auc_test = roc_auc_score(y_test, y_test_proba)\n",
    "auprc_test = average_precision_score(y_test, y_test_proba)\n",
    "print(f\"Test ROC AUC: {roc_auc_test:.3f}, AUPRC: {auprc_test:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there is a total of 215 features exctracted, we'll try with some regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation with Logistic Regression (l2-reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Best regularization parameter (C): 0.01\n",
      "Validation ROC AUC: 0.829, AUPRC: 0.458\n",
      "Test ROC AUC: 0.827, AUPRC: 0.487\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# --- Scale the features ---\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the training data and transform\n",
    "X_train_scaled = scaler.fit_transform(X_train_relevant)\n",
    "\n",
    "# Transform the validation and test sets using the same scaler\n",
    "X_val_scaled = scaler.transform(X_val_relevant)\n",
    "X_test_scaled = scaler.transform(X_test_relevant)\n",
    "\n",
    "# --- Define the Logistic Regression model ---\n",
    "# Use L2 regularization (default) and set up the solver\n",
    "log_reg = LogisticRegression(random_state=42, max_iter=5000, penalty='l2', solver='liblinear')\n",
    "\n",
    "# --- Set up the grid search for hyperparameter tuning ---\n",
    "# Define the range of C values to test\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]}\n",
    "\n",
    "# Use ROC AUC as the scoring metric for grid search\n",
    "grid_search = GridSearchCV(estimator=log_reg, param_grid=param_grid, scoring='roc_auc', cv=5, verbose=1)\n",
    "\n",
    "# --- Perform grid search on the training data ---\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# --- Get the best model and its parameters ---\n",
    "best_clf = grid_search.best_estimator_\n",
    "best_C = grid_search.best_params_['C']\n",
    "print(f\"Best regularization parameter (C): {best_C}\")\n",
    "\n",
    "# --- Evaluate on the validation set using the best model ---\n",
    "y_val_proba = best_clf.predict_proba(X_val_scaled)[:, 1]  # Probability for the positive class\n",
    "roc_auc_val = roc_auc_score(y_val, y_val_proba)\n",
    "auprc_val = average_precision_score(y_val, y_val_proba)\n",
    "print(f\"Validation ROC AUC: {roc_auc_val:.3f}, AUPRC: {auprc_val:.3f}\")\n",
    "\n",
    "# --- Evaluate on the test set using the best model ---\n",
    "y_test_proba = best_clf.predict_proba(X_test_scaled)[:, 1]\n",
    "roc_auc_test = roc_auc_score(y_test, y_test_proba)\n",
    "auprc_test = average_precision_score(y_test, y_test_proba)\n",
    "print(f\"Test ROC AUC: {roc_auc_test:.3f}, AUPRC: {auprc_test:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation with Logistic Regression (l1- reg)\n",
    "\n",
    "Since Lasso convergence is slower, we improved it by using the saga solver, increasing the iterations, adjusting the tolerance and also doing the grid search with every processor (n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Best regularization parameter (C): 0.1\n",
      "Validation ROC AUC: 0.834, AUPRC: 0.472\n",
      "Test ROC AUC: 0.832, AUPRC: 0.491\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# --- Scale the features ---\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_relevant)\n",
    "X_val_scaled = scaler.transform(X_val_relevant)\n",
    "X_test_scaled = scaler.transform(X_test_relevant)\n",
    "\n",
    "# --- Define the Logistic Regression model with L1 regularization ---\n",
    "log_reg = LogisticRegression(\n",
    "    penalty='l1', \n",
    "    solver='saga', \n",
    "    max_iter=5000,  # Increase max_iter\n",
    "    tol=1e-3,       # Adjust tolerance\n",
    "    warm_start=True, # Enable warm start\n",
    "    random_state=42\n",
    ")\n",
    "# --- Set up the grid search for hyperparameter tuning ---\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]}\n",
    "grid_search = GridSearchCV(estimator=log_reg, param_grid=param_grid, scoring='roc_auc', cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "# --- Perform grid search on the training data ---\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# --- Get the best model and its parameters ---\n",
    "best_clf = grid_search.best_estimator_\n",
    "best_C = grid_search.best_params_['C']\n",
    "print(f\"Best regularization parameter (C): {best_C}\")\n",
    "\n",
    "# --- Evaluate on the validation set using the best model ---\n",
    "y_val_proba = best_clf.predict_proba(X_val_scaled)[:, 1]\n",
    "roc_auc_val = roc_auc_score(y_val, y_val_proba)\n",
    "auprc_val = average_precision_score(y_val, y_val_proba)\n",
    "print(f\"Validation ROC AUC: {roc_auc_val:.3f}, AUPRC: {auprc_val:.3f}\")\n",
    "\n",
    "# --- Evaluate on the test set using the best model ---\n",
    "y_test_proba = best_clf.predict_proba(X_test_scaled)[:, 1]\n",
    "roc_auc_test = roc_auc_score(y_test, y_test_proba)\n",
    "auprc_test = average_precision_score(y_test, y_test_proba)\n",
    "print(f\"Test ROC AUC: {roc_auc_test:.3f}, AUPRC: {auprc_test:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best hyperparameters: {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2', 'max_depth': 20}\n",
      "Validation ROC AUC: 0.825, AUPRC: 0.450\n",
      "Test ROC AUC: 0.825, AUPRC: 0.484\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import numpy as np\n",
    "\n",
    "# --- Define the Random Forest Classifier ---\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)  # Use all CPU cores\n",
    "\n",
    "# --- Set up the randomized search for hyperparameter tuning ---\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200],  # Number of trees\n",
    "    'max_depth': [10, 20],       # Maximum depth of each tree\n",
    "    'min_samples_split': [2, 5], # Minimum samples to split a node\n",
    "    'min_samples_leaf': [1, 2],  # Minimum samples at each leaf node\n",
    "    'max_features': ['sqrt', 'log2']  # Number of features to consider at each split\n",
    "}\n",
    "\n",
    "# Use RandomizedSearchCV with a fixed number of iterations\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,  # Number of hyperparameter combinations to try\n",
    "    scoring='roc_auc',\n",
    "    cv=5,\n",
    "    n_jobs=-1,  # Use all CPU cores\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# --- Perform randomized search on the training data ---\n",
    "random_search.fit(X_train_relevant, y_train)\n",
    "\n",
    "# --- Get the best model and its parameters ---\n",
    "best_clf = random_search.best_estimator_\n",
    "best_params = random_search.best_params_\n",
    "print(f\"Best hyperparameters: {best_params}\")\n",
    "\n",
    "# --- Evaluate on the validation set using the best model ---\n",
    "y_val_proba = best_clf.predict_proba(X_val_relevant)[:, 1]  # Probability for the positive class\n",
    "roc_auc_val = roc_auc_score(y_val, y_val_proba)\n",
    "auprc_val = average_precision_score(y_val, y_val_proba)\n",
    "print(f\"Validation ROC AUC: {roc_auc_val:.3f}, AUPRC: {auprc_val:.3f}\")\n",
    "\n",
    "# --- Evaluate on the test set using the best model ---\n",
    "y_test_proba = best_clf.predict_proba(X_test_relevant)[:, 1]\n",
    "roc_auc_test = roc_auc_score(y_test, y_test_proba)\n",
    "auprc_test = average_precision_score(y_test, y_test_proba)\n",
    "print(f\"Test ROC AUC: {roc_auc_test:.3f}, AUPRC: {auprc_test:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without hyperparameter tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation ROC AUC: 0.799, AUPRC: 0.395\n",
      "Test ROC AUC: 0.811, AUPRC: 0.452\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "# --- Definisci il modello Random Forest con parametri predefiniti ---\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)  # Usa tutti i core della CPU\n",
    "\n",
    "# --- Addestra il modello sui dati di training ---\n",
    "rf.fit(X_train_relevant, y_train)\n",
    "\n",
    "# --- Valuta sul validation set ---\n",
    "y_val_proba = rf.predict_proba(X_val_relevant)[:, 1]  # Probabilità per la classe positiva\n",
    "roc_auc_val = roc_auc_score(y_val, y_val_proba)\n",
    "auprc_val = average_precision_score(y_val, y_val_proba)\n",
    "print(f\"Validation ROC AUC: {roc_auc_val:.3f}, AUPRC: {auprc_val:.3f}\")\n",
    "\n",
    "# --- Valuta sul test set ---\n",
    "y_test_proba = rf.predict_proba(X_test_relevant)[:, 1]\n",
    "roc_auc_test = roc_auc_score(y_test, y_test_proba)\n",
    "auprc_test = average_precision_score(y_test, y_test_proba)\n",
    "print(f\"Test ROC AUC: {roc_auc_test:.3f}, AUPRC: {auprc_test:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
