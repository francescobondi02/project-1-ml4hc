{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-24 17:03:19.746\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproject_1.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mPROJ_ROOT path is: /Users/francescobondi/Desktop/stuff/ETH/FS25/ML for Healthcare/project-1-ml4hc\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from project_1.config import PROJ_ROOT, PROCESSED_DATA_DIR\n",
    "from project_1.loading import *\n",
    "from project_1.dataset import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "For basic LSTM, we load the final datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of the datasets:\n",
      "Set A: (183416, 42) Set B: (183495, 42) Set C: (183711, 42)\n",
      "Shapes of labels:\n",
      "Set A: (4000, 2) Set B: (4000, 2) Set C: (4000, 2)\n"
     ]
    }
   ],
   "source": [
    "set_a, set_b, set_c = load_final_data_without_ICU()\n",
    "death_a, death_b, death_c = load_outcomes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 1 - LSTM - Model Implementation (Last State)\n",
    "This basic implementation takes the last hidden state to be used for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=64, num_layers=2, num_classes=1, dropout=0.3):\n",
    "        super(LSTM_Model, self).__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,       # 41 features per time step\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, seq_len, input_size)\n",
    "        out, _ = self.lstm(x)           # out: (batch_size, seq_len, hidden_size)\n",
    "        out = out[:, -1, :]             # Take last time step: (batch_size, hidden_size)\n",
    "        out = self.fc(out)              # (batch_size, num_classes)\n",
    "        return out.squeeze()            # (batch_size,) for BCEWithLogitsLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain TensorDatasets from Time Series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4000, 49, 40])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = create_dataset_from_timeseries(set_a, death_a[\"In-hospital_death\"])\n",
    "validation_dataset = create_dataset_from_timeseries(set_b, death_b[\"In-hospital_death\"])\n",
    "test_dataset = create_dataset_from_timeseries(set_c, death_c[\"In-hospital_death\"])\n",
    "\n",
    "train_dataset.tensors[0].shape # (batch_size, seq_len, input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francescobondi/anaconda3/envs/TUM/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  Train Loss: 0.4497 | AUCROC: 0.5604 | AUPRC: 0.1566\n",
      "  Val   Loss: 0.3547 | AUCROC: 0.7660 | AUPRC: 0.4106\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "  Train Loss: 0.3358 | AUCROC: 0.7849 | AUPRC: 0.4156\n",
      "  Val   Loss: 0.3323 | AUCROC: 0.8149 | AUPRC: 0.4619\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "  Train Loss: 0.3067 | AUCROC: 0.8345 | AUPRC: 0.4951\n",
      "  Val   Loss: 0.3138 | AUCROC: 0.8346 | AUPRC: 0.4585\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "  Train Loss: 0.2879 | AUCROC: 0.8594 | AUPRC: 0.5262\n",
      "  Val   Loss: 0.3149 | AUCROC: 0.8301 | AUPRC: 0.4593\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "  Train Loss: 0.2695 | AUCROC: 0.8770 | AUPRC: 0.5970\n",
      "  Val   Loss: 0.3277 | AUCROC: 0.8309 | AUPRC: 0.4490\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "  Train Loss: 0.2519 | AUCROC: 0.8945 | AUPRC: 0.6322\n",
      "  Val   Loss: 0.3224 | AUCROC: 0.8280 | AUPRC: 0.4475\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "  Train Loss: 0.2304 | AUCROC: 0.9111 | AUPRC: 0.7019\n",
      "  Val   Loss: 0.3425 | AUCROC: 0.8247 | AUPRC: 0.4335\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "  Train Loss: 0.2229 | AUCROC: 0.9179 | AUPRC: 0.7137\n",
      "  Val   Loss: 0.3426 | AUCROC: 0.8170 | AUPRC: 0.4170\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "  Train Loss: 0.2086 | AUCROC: 0.9274 | AUPRC: 0.7494\n",
      "  Val   Loss: 0.3892 | AUCROC: 0.8181 | AUPRC: 0.4271\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "  Train Loss: 0.1877 | AUCROC: 0.9429 | AUPRC: 0.7939\n",
      "  Val   Loss: 0.4143 | AUCROC: 0.8162 | AUPRC: 0.4330\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_size = train_dataset.tensors[0].shape[-1]\n",
    "model = LSTM_Model(input_size=input_size).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Call the trainig loop (default 10 epochs)\n",
    "model = train_model_with_validation(model, train_loader, validation_loader, criterion, optimizer, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation - Loss: 0.4082 - AUCROC: 0.8151 - AUPRC: 0.4571\n",
      "Test Loss: 0.4082, AUC-ROC: 0.8151, AUC-PRC: 0.4571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "avg_loss, aucroc, auprc = evaluate_model(model, test_loader, criterion, device)\n",
    "print(f\"Test Loss: {avg_loss:.4f}, AUC-ROC: {aucroc:.4f}, AUC-PRC: {auprc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 2 - LSTM - Model Implementation (Mean Pooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Model_Pooling(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=64, num_layers=2, num_classes=1, dropout=0.3):\n",
    "        super(LSTM_Model_Pooling, self).__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,       # 40 features per time step\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, seq_len, input_size)\n",
    "        out, _ = self.lstm(x)           # out: (batch_size, seq_len, hidden_size)\n",
    "        out = out.mean(dim=1)           # Pooling: (batch_size, hidden_size)   \n",
    "        out = self.fc(out)              # (batch_size, num_classes)\n",
    "        return out.squeeze()            # (batch_size,) for BCEWithLogitsLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  Train Loss: 0.4303 | AUCROC: 0.5825 | AUPRC: 0.1721\n",
      "  Val   Loss: 0.3578 | AUCROC: 0.7557 | AUPRC: 0.3545\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "  Train Loss: 0.3372 | AUCROC: 0.7851 | AUPRC: 0.3899\n",
      "  Val   Loss: 0.3359 | AUCROC: 0.7962 | AUPRC: 0.3973\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "  Train Loss: 0.3172 | AUCROC: 0.8206 | AUPRC: 0.4467\n",
      "  Val   Loss: 0.3271 | AUCROC: 0.8122 | AUPRC: 0.4244\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "  Train Loss: 0.3038 | AUCROC: 0.8403 | AUPRC: 0.4773\n",
      "  Val   Loss: 0.3369 | AUCROC: 0.8124 | AUPRC: 0.4237\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "  Train Loss: 0.2898 | AUCROC: 0.8596 | AUPRC: 0.5134\n",
      "  Val   Loss: 0.3544 | AUCROC: 0.8060 | AUPRC: 0.4219\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "  Train Loss: 0.2732 | AUCROC: 0.8784 | AUPRC: 0.5749\n",
      "  Val   Loss: 0.3342 | AUCROC: 0.8169 | AUPRC: 0.4144\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "  Train Loss: 0.2632 | AUCROC: 0.8893 | AUPRC: 0.5920\n",
      "  Val   Loss: 0.3268 | AUCROC: 0.8192 | AUPRC: 0.4318\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "  Train Loss: 0.2405 | AUCROC: 0.9123 | AUPRC: 0.6384\n",
      "  Val   Loss: 0.3790 | AUCROC: 0.8030 | AUPRC: 0.4090\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "  Train Loss: 0.2213 | AUCROC: 0.9270 | AUPRC: 0.6865\n",
      "  Val   Loss: 0.3855 | AUCROC: 0.8059 | AUPRC: 0.4194\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "  Train Loss: 0.2070 | AUCROC: 0.9373 | AUPRC: 0.7342\n",
      "  Val   Loss: 0.4794 | AUCROC: 0.7844 | AUPRC: 0.3979\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Use the previous data loaders and train the new model\n",
    "model_pooling = LSTM_Model_Pooling(input_size=input_size).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model_pooling.parameters(), lr=0.001)\n",
    "\n",
    "model_pooling = train_model_with_validation(model_pooling, train_loader, validation_loader, criterion, optimizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation - Loss: 0.4467 - AUCROC: 0.7894 - AUPRC: 0.4138\n",
      "Test Loss: 0.4467, AUC-ROC: 0.7894, AUC-PRC: 0.4138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Now evaluate the model\n",
    "avg_loss, aucroc, auprc = evaluate_model(model_pooling, test_loader, criterion, device)\n",
    "print(f\"Test Loss: {avg_loss:.4f}, AUC-ROC: {aucroc:.4f}, AUC-PRC: {auprc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 3 - Bidirectional LSTM - Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Model_Bi(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=64, num_layers=2, num_classes=1, dropout=0.3):\n",
    "        super(LSTM_Model_Bi, self).__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,       # 41 features per time step\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_classes) # *2 for bidirectional\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, seq_len, input_size)\n",
    "        out, _ = self.lstm(x)           # out: (batch_size, seq_len, hidden_size)\n",
    "        out = out[:, -1, :]             # Take last time step: (batch_size, hidden_size)\n",
    "        out = self.fc(out)              # (batch_size, num_classes)\n",
    "        return out.squeeze()            # (batch_size,) for BCEWithLogitsLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  Train Loss: 0.4344 | AUCROC: 0.6091 | AUPRC: 0.1905\n",
      "  Val   Loss: 0.3563 | AUCROC: 0.7748 | AUPRC: 0.4063\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "  Train Loss: 0.3251 | AUCROC: 0.8053 | AUPRC: 0.4253\n",
      "  Val   Loss: 0.3240 | AUCROC: 0.8168 | AUPRC: 0.4521\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "  Train Loss: 0.3040 | AUCROC: 0.8380 | AUPRC: 0.4865\n",
      "  Val   Loss: 0.3178 | AUCROC: 0.8239 | AUPRC: 0.4602\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "  Train Loss: 0.2859 | AUCROC: 0.8616 | AUPRC: 0.5321\n",
      "  Val   Loss: 0.3152 | AUCROC: 0.8315 | AUPRC: 0.4608\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "  Train Loss: 0.2695 | AUCROC: 0.8804 | AUPRC: 0.5854\n",
      "  Val   Loss: 0.3305 | AUCROC: 0.8288 | AUPRC: 0.4489\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "  Train Loss: 0.2503 | AUCROC: 0.8995 | AUPRC: 0.6372\n",
      "  Val   Loss: 0.3307 | AUCROC: 0.8395 | AUPRC: 0.4628\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "  Train Loss: 0.2296 | AUCROC: 0.9169 | AUPRC: 0.6813\n",
      "  Val   Loss: 0.3777 | AUCROC: 0.8178 | AUPRC: 0.4408\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "  Train Loss: 0.2167 | AUCROC: 0.9259 | AUPRC: 0.7237\n",
      "  Val   Loss: 0.3786 | AUCROC: 0.8266 | AUPRC: 0.4423\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "  Train Loss: 0.1980 | AUCROC: 0.9374 | AUPRC: 0.7709\n",
      "  Val   Loss: 0.3929 | AUCROC: 0.8158 | AUPRC: 0.4355\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "  Train Loss: 0.1772 | AUCROC: 0.9486 | AUPRC: 0.8204\n",
      "  Val   Loss: 0.4428 | AUCROC: 0.8114 | AUPRC: 0.4183\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model_bi = LSTM_Model_Bi(input_size=input_size).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model_bi.parameters(), lr=0.001)\n",
    "\n",
    "model_bi = train_model_with_validation(model_bi, train_loader, validation_loader, criterion, optimizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation - Loss: 0.4351 - AUCROC: 0.8020 - AUPRC: 0.4309\n",
      "Test Loss: 0.4351, AUC-ROC: 0.8020, AUC-PRC: 0.4309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Now evaluate\n",
    "avg_loss, aucroc, auprc = evaluate_model(model_bi, test_loader, criterion, device)\n",
    "print(f\"Test Loss: {avg_loss:.4f}, AUC-ROC: {aucroc:.4f}, AUC-PRC: {auprc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformers - Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn\n",
    "\n",
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, input_size, num_classes=1, nhead=4, num_layers=2, dim_feedforward=128, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "\n",
    "        # Project input features to model dimension\n",
    "        self.embedding = nn.Linear(input_size, dim_feedforward)\n",
    "\n",
    "        # Positional Encoding\n",
    "        self.pos_encoder = PositionalEncoding(dim_feedforward, dropout)\n",
    "\n",
    "        # Transformer Encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=dim_feedforward,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward * 2,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        # Final classifier\n",
    "        self.fc = nn.Linear(dim_feedforward, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_len, input_size)\n",
    "        x = self.embedding(x)                # (batch, seq_len, d_model)\n",
    "        x = self.pos_encoder(x)\n",
    "        x = self.transformer_encoder(x)      # (batch, seq_len, d_model)\n",
    "\n",
    "        x = x.mean(dim=1)                    # mean pooling over time\n",
    "        out = self.fc(x).squeeze()           # (batch,)\n",
    "        return out\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=500):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)  # (max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(torch.log(torch.tensor(10000.0)) / d_model))\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)  # (1, max_len, d_model)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  Train Loss: 0.3753 | AUCROC: 0.6900 | AUPRC: 0.2777\n",
      "  Val   Loss: 0.3934 | AUCROC: 0.7895 | AUPRC: 0.3990\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "  Train Loss: 0.3372 | AUCROC: 0.7825 | AUPRC: 0.3873\n",
      "  Val   Loss: 0.3414 | AUCROC: 0.8046 | AUPRC: 0.4048\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "  Train Loss: 0.3256 | AUCROC: 0.8034 | AUPRC: 0.4247\n",
      "  Val   Loss: 0.3268 | AUCROC: 0.8188 | AUPRC: 0.4287\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "  Train Loss: 0.3217 | AUCROC: 0.8135 | AUPRC: 0.4283\n",
      "  Val   Loss: 0.3304 | AUCROC: 0.8255 | AUPRC: 0.4381\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "  Train Loss: 0.3080 | AUCROC: 0.8324 | AUPRC: 0.4729\n",
      "  Val   Loss: 0.3290 | AUCROC: 0.8247 | AUPRC: 0.4555\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "  Train Loss: 0.3043 | AUCROC: 0.8369 | AUPRC: 0.4933\n",
      "  Val   Loss: 0.3434 | AUCROC: 0.7989 | AUPRC: 0.4113\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "  Train Loss: 0.2927 | AUCROC: 0.8530 | AUPRC: 0.5238\n",
      "  Val   Loss: 0.3677 | AUCROC: 0.8188 | AUPRC: 0.4131\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "  Train Loss: 0.2880 | AUCROC: 0.8574 | AUPRC: 0.5443\n",
      "  Val   Loss: 0.3782 | AUCROC: 0.8138 | AUPRC: 0.3918\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "  Train Loss: 0.2808 | AUCROC: 0.8658 | AUPRC: 0.5638\n",
      "  Val   Loss: 0.3890 | AUCROC: 0.8075 | AUPRC: 0.3864\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "  Train Loss: 0.2777 | AUCROC: 0.8709 | AUPRC: 0.5644\n",
      "  Val   Loss: 0.4118 | AUCROC: 0.8173 | AUPRC: 0.4136\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Train the Transformer model\n",
    "model_transformer = TransformerClassifier(input_size=input_size).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model_transformer.parameters(), lr=0.001)\n",
    "\n",
    "model_transformer = train_model_with_validation(model_transformer, train_loader, validation_loader, criterion, optimizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation - Loss: 0.3697 - AUCROC: 0.8141 - AUPRC: 0.4395\n",
      "Test Loss: 0.3697, AUC-ROC: 0.8141, AUC-PRC: 0.4395\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "avg_loss, aucroc, auprc = evaluate_model(model_transformer, test_loader, criterion, device)\n",
    "print(f\"Test Loss: {avg_loss:.4f}, AUC-ROC: {aucroc:.4f}, AUC-PRC: {auprc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2.3 - Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of the datasets:\n",
      "Set A: (183416, 43) Set B: (183495, 43) Set C: (183711, 43)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordID</th>\n",
       "      <th>Time</th>\n",
       "      <th>Age</th>\n",
       "      <th>BUN</th>\n",
       "      <th>Creatinine</th>\n",
       "      <th>GCS</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>HCO3</th>\n",
       "      <th>HCT</th>\n",
       "      <th>...</th>\n",
       "      <th>PaCO2</th>\n",
       "      <th>PaO2</th>\n",
       "      <th>pH</th>\n",
       "      <th>DiasABP</th>\n",
       "      <th>MAP</th>\n",
       "      <th>SaO2</th>\n",
       "      <th>SysABP</th>\n",
       "      <th>Lactate</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>TroponinI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>132539.0</td>\n",
       "      <td>2025-03-10 00:00:00</td>\n",
       "      <td>54.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132539.0</td>\n",
       "      <td>2025-03-10 01:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>132539.0</td>\n",
       "      <td>2025-03-10 02:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132539.0</td>\n",
       "      <td>2025-03-10 03:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132539.0</td>\n",
       "      <td>2025-03-10 04:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.7</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RecordID                Time   Age  BUN  Creatinine   GCS  Gender  Glucose  \\\n",
       "0  132539.0 2025-03-10 00:00:00  54.0  NaN         NaN   NaN     0.0      NaN   \n",
       "1  132539.0 2025-03-10 01:00:00   NaN  NaN         NaN  15.0     NaN      NaN   \n",
       "2  132539.0 2025-03-10 02:00:00   NaN  NaN         NaN   NaN     NaN      NaN   \n",
       "3  132539.0 2025-03-10 03:00:00   NaN  NaN         NaN   NaN     NaN      NaN   \n",
       "4  132539.0 2025-03-10 04:00:00   NaN  NaN         NaN  15.0     NaN      NaN   \n",
       "\n",
       "   HCO3   HCT  ...  PaCO2  PaO2  pH  DiasABP  MAP  SaO2  SysABP  Lactate  \\\n",
       "0   NaN   NaN  ...    NaN   NaN NaN      NaN  NaN   NaN     NaN      NaN   \n",
       "1   NaN   NaN  ...    NaN   NaN NaN      NaN  NaN   NaN     NaN      NaN   \n",
       "2   NaN   NaN  ...    NaN   NaN NaN      NaN  NaN   NaN     NaN      NaN   \n",
       "3   NaN   NaN  ...    NaN   NaN NaN      NaN  NaN   NaN     NaN      NaN   \n",
       "4   NaN  33.7  ...    NaN   NaN NaN      NaN  NaN   NaN     NaN      NaN   \n",
       "\n",
       "   Cholesterol  TroponinI  \n",
       "0          NaN        NaN  \n",
       "1          NaN        NaN  \n",
       "2          NaN        NaN  \n",
       "3          NaN        NaN  \n",
       "4          NaN        NaN  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For this part, we need to load the initial data\n",
    "set_a_initial, set_b_initial, set_c_initial = load_basic_data()\n",
    "set_a_initial.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the TZV Dataframe (following Horn et al.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def build_TZV_dataframe(original_df, labels, base_time=\"2025-03-10 00:00:00\", duration_hours=48):\n",
    "    df = original_df.copy()\n",
    "\n",
    "    # Convert time to datetime\n",
    "    df[\"Time\"] = pd.to_datetime(df[\"Time\"])\n",
    "    start_time = pd.to_datetime(base_time)\n",
    "    end_time = start_time + pd.Timedelta(hours=duration_hours)\n",
    "\n",
    "    # Normalize time into [0, 1]\n",
    "    total_seconds = (end_time - start_time).total_seconds()\n",
    "    df[\"T\"] = (df[\"Time\"] - start_time).dt.total_seconds() / total_seconds\n",
    "\n",
    "    # Drop RecordID if not needed\n",
    "    feature_cols = [col for col in df.columns if col not in [\"RecordID\", \"Time\", \"T\"]]\n",
    "\n",
    "    # Scale each feature individually (min-max)\n",
    "    scaler = MinMaxScaler()\n",
    "    df_scaled = df[feature_cols].copy()\n",
    "    df_scaled[feature_cols] = scaler.fit_transform(df_scaled[feature_cols])\n",
    "\n",
    "    # Stack into long format\n",
    "    long_df = df_scaled.melt(ignore_index=False, value_vars=feature_cols, var_name=\"Z\", value_name=\"V\")\n",
    "    long_df = long_df.reset_index(drop=True)\n",
    "\n",
    "    # Add corresponding scaled time\n",
    "    repeated_T = np.repeat(df[\"T\"].values, len(feature_cols))\n",
    "    long_df[\"T\"] = repeated_T\n",
    "\n",
    "    # Remove NaNs (measurements not taken)\n",
    "    long_df = long_df.dropna(subset=[\"V\"])\n",
    "\n",
    "    # Map feature names to indices\n",
    "    feature_to_index = {feat: idx for idx, feat in enumerate(feature_cols)}\n",
    "    long_df[\"Z\"] = long_df[\"Z\"].map(feature_to_index)\n",
    "\n",
    "    # Reorder columns\n",
    "    long_df = long_df[[\"T\", \"Z\", \"V\"]].sort_values(\"T\").reset_index(drop=True)\n",
    "\n",
    "    return long_df, feature_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1456736, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T</th>\n",
       "      <th>Z</th>\n",
       "      <th>V</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>34</td>\n",
       "      <td>0.276119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>34</td>\n",
       "      <td>0.283582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>34</td>\n",
       "      <td>0.272388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>34</td>\n",
       "      <td>0.302239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     T   Z         V\n",
       "0  0.0   0  0.520000\n",
       "1  0.0  34  0.276119\n",
       "2  0.0  34  0.283582\n",
       "3  0.0  34  0.272388\n",
       "4  0.0  34  0.302239"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the TZV dataframes\n",
    "TZV_a, feature_to_index_a = build_TZV_dataframe(set_a_initial)\n",
    "TZV_b, feature_to_index_b = build_TZV_dataframe(set_b_initial)\n",
    "TZV_c, feature_to_index_c = build_TZV_dataframe(set_c_initial)\n",
    "\n",
    "print(TZV_a.shape)\n",
    "TZV_a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1456736"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for the total number of not NaN values under some specified columns\n",
    "selected_cols = [col for col in set_a_initial.columns if col not in [\"RecordID\", \"Time\"]]\n",
    "set_a_initial[selected_cols].notna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checked that the number of not NaN values is the same as the rows of the new dataframe! Let's go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TUM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
