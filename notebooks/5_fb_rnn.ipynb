{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN - LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from project_1.config import PROJ_ROOT, PROCESSED_DATA_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load _final.parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 2)\n",
      "(183416, 43)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordID</th>\n",
       "      <th>Time</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Age</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>DiasABP</th>\n",
       "      <th>HCO3</th>\n",
       "      <th>...</th>\n",
       "      <th>Urine</th>\n",
       "      <th>WBC</th>\n",
       "      <th>pH</th>\n",
       "      <th>MechVent</th>\n",
       "      <th>TroponinT</th>\n",
       "      <th>ALP</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AST</th>\n",
       "      <th>Bilirubin</th>\n",
       "      <th>TroponinI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>132539.0</td>\n",
       "      <td>2025-03-10 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.950526</td>\n",
       "      <td>-0.23008</td>\n",
       "      <td>-0.596332</td>\n",
       "      <td>1.671639</td>\n",
       "      <td>-0.013487</td>\n",
       "      <td>-0.832594</td>\n",
       "      <td>-0.109176</td>\n",
       "      <td>...</td>\n",
       "      <td>11.571429</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>1.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.923077</td>\n",
       "      <td>0.132075</td>\n",
       "      <td>-0.176471</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>1.545455</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132539.0</td>\n",
       "      <td>2025-03-10 01:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.950526</td>\n",
       "      <td>-0.23008</td>\n",
       "      <td>-0.596332</td>\n",
       "      <td>1.967793</td>\n",
       "      <td>0.172112</td>\n",
       "      <td>-0.608431</td>\n",
       "      <td>-0.109176</td>\n",
       "      <td>...</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>-0.420290</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.246154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.294118</td>\n",
       "      <td>0.436620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.126984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>132539.0</td>\n",
       "      <td>2025-03-10 02:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.950526</td>\n",
       "      <td>-0.23008</td>\n",
       "      <td>-0.596332</td>\n",
       "      <td>-1.734132</td>\n",
       "      <td>0.125712</td>\n",
       "      <td>0.848629</td>\n",
       "      <td>0.830987</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.357143</td>\n",
       "      <td>-0.014493</td>\n",
       "      <td>-0.875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.773585</td>\n",
       "      <td>-0.205882</td>\n",
       "      <td>-0.380282</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>-0.095238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132539.0</td>\n",
       "      <td>2025-03-10 03:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.950526</td>\n",
       "      <td>-0.23008</td>\n",
       "      <td>-0.596332</td>\n",
       "      <td>1.523562</td>\n",
       "      <td>0.380910</td>\n",
       "      <td>-0.832594</td>\n",
       "      <td>-0.579257</td>\n",
       "      <td>...</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.188406</td>\n",
       "      <td>-0.375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.215385</td>\n",
       "      <td>-0.698113</td>\n",
       "      <td>-0.588235</td>\n",
       "      <td>1.126761</td>\n",
       "      <td>-0.181818</td>\n",
       "      <td>4.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132539.0</td>\n",
       "      <td>2025-03-10 04:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.950526</td>\n",
       "      <td>-0.23008</td>\n",
       "      <td>-0.596332</td>\n",
       "      <td>0.487023</td>\n",
       "      <td>-0.964680</td>\n",
       "      <td>1.483758</td>\n",
       "      <td>-0.814297</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.142857</td>\n",
       "      <td>-1.144928</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.738462</td>\n",
       "      <td>-0.490566</td>\n",
       "      <td>-0.558824</td>\n",
       "      <td>-0.225352</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RecordID                Time  Gender    Height   Weight       Age  \\\n",
       "0  132539.0 2025-03-10 00:00:00     0.0 -0.950526 -0.23008 -0.596332   \n",
       "1  132539.0 2025-03-10 01:00:00     0.0 -0.950526 -0.23008 -0.596332   \n",
       "2  132539.0 2025-03-10 02:00:00     0.0 -0.950526 -0.23008 -0.596332   \n",
       "3  132539.0 2025-03-10 03:00:00     0.0 -0.950526 -0.23008 -0.596332   \n",
       "4  132539.0 2025-03-10 04:00:00     0.0 -0.950526 -0.23008 -0.596332   \n",
       "\n",
       "    Albumin  Cholesterol   DiasABP      HCO3  ...      Urine       WBC     pH  \\\n",
       "0  1.671639    -0.013487 -0.832594 -0.109176  ...  11.571429  0.753623  1.125   \n",
       "1  1.967793     0.172112 -0.608431 -0.109176  ...   2.857143 -0.420290  0.125   \n",
       "2 -1.734132     0.125712  0.848629  0.830987  ...  -0.357143 -0.014493 -0.875   \n",
       "3  1.523562     0.380910 -0.832594 -0.579257  ...   0.642857  0.188406 -0.375   \n",
       "4  0.487023    -0.964680  1.483758 -0.814297  ...  -0.142857 -1.144928  1.000   \n",
       "\n",
       "   MechVent  TroponinT       ALP       ALT       AST  Bilirubin  TroponinI  \n",
       "0       0.0   1.923077  0.132075 -0.176471  0.450704   1.545455   0.285714  \n",
       "1       0.0  -0.246154  0.000000 -0.294118  0.436620   0.000000  -0.126984  \n",
       "2       0.0   0.000000  0.773585 -0.205882 -0.380282   0.181818  -0.095238  \n",
       "3       0.0   0.215385 -0.698113 -0.588235  1.126761  -0.181818   4.650794  \n",
       "4       0.0   2.738462 -0.490566 -0.558824 -0.225352   0.363636   0.904762  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data from Parquet files\n",
    "sets_dict = {}\n",
    "sets = [\"a\", \"b\", \"c\"]\n",
    "\n",
    "for set_name in sets:\n",
    "    directory = PROCESSED_DATA_DIR / f\"set_{set_name}_final.parquet\"\n",
    "    temp_set = pd.read_parquet(directory)\n",
    "    sets_dict[f\"set_{set_name}\"] = temp_set\n",
    "\n",
    "# Define file names\n",
    "file_names = [\"Outcomes-a.txt\", \"Outcomes-b.txt\", \"Outcomes-c.txt\"]\n",
    "\n",
    "# Directory path\n",
    "base_path = PROJ_ROOT / \"data\" / \"data_1\" / \"predicting-mortality-of-icu-patients-the-physionet-computing-in-cardiology-challenge-2012-1.0.0\"\n",
    "\n",
    "# Read files into DataFrames containing all variables\n",
    "outcomes_a, outcomes_b, outcomes_c = [pd.read_csv(base_path / name) for name in file_names]\n",
    "\n",
    "# Extract only the \"RecordID\" and \"In-hospital_death\" column into separate DataFrames\n",
    "death_a, death_b, death_c = [df[[\"RecordID\", \"In-hospital_death\"]] for df in [outcomes_a, outcomes_b, outcomes_c]]\n",
    "print(death_a.shape)\n",
    "\n",
    "#CHECK for missing values in the outcome data\n",
    "\"\"\"print(death_a.isnull().sum())\n",
    "print(death_b.isnull().sum())\n",
    "print(death_c.isnull().sum())\"\"\"\n",
    "# Assure the loading was correct\n",
    "print(sets_dict[\"set_a\"].shape)\n",
    "sets_dict[\"set_a\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.5 -0.5  0.  -1. ]\n"
     ]
    }
   ],
   "source": [
    "# Check if ICUType is present\n",
    "print(sets_dict[\"set_a\"].ICUType.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove ICUType from the data\n",
    "if \"ICUType\" in sets_dict[\"set_a\"].columns:\n",
    "    sets_dict[\"set_a\"] = sets_dict[\"set_a\"].drop(columns=[\"ICUType\"])\n",
    "\n",
    "if \"ICUType\" in sets_dict[\"set_b\"].columns:\n",
    "    sets_dict[\"set_b\"] = sets_dict[\"set_b\"].drop(columns=[\"ICUType\"])\n",
    "\n",
    "if \"ICUType\" in sets_dict[\"set_c\"].columns:\n",
    "    sets_dict[\"set_c\"] = sets_dict[\"set_c\"].drop(columns=[\"ICUType\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Implementation of LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=64, num_layers=2, num_classes=1, dropout=0.3):\n",
    "        super(LSTM_Model, self).__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,       # 41 features per time step\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, seq_len, input_size)\n",
    "        out, _ = self.lstm(x)           # out: (batch_size, seq_len, hidden_size)\n",
    "        out = out[:, -1, :]             # Take last time step: (batch_size, hidden_size)\n",
    "        out = self.fc(out)              # (batch_size, num_classes)\n",
    "        return out.squeeze()            # (batch_size,) for BCEWithLogitsLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre process Dataframe => Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([48, 40]), torch.Size([47, 40]))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only convert sets A and C\n",
    "\n",
    "# Convert the sets to PyTorch tensors\n",
    "features_cols = [col for col in sets_dict[\"set_a\"].columns if col not in [\"RecordID\", \"Time\"]]\n",
    "\n",
    "sequences_a = []\n",
    "sequences_c = []\n",
    "set_a = sets_dict[\"set_a\"]\n",
    "set_c = sets_dict[\"set_c\"]\n",
    "for record_id, group in set_a.groupby(\"RecordID\"):\n",
    "    seq = group[features_cols].to_numpy(dtype=np.float32)\n",
    "    sequences_a.append(torch.tensor(seq))\n",
    "\n",
    "for record_id, group in set_c.groupby(\"RecordID\"):\n",
    "    seq = group[features_cols].to_numpy(dtype=np.float32)\n",
    "    sequences_c.append(torch.tensor(seq))\n",
    "\n",
    "# Now sequences_a is a list of PyTorch tensors, of shape (48, 41) each (48 timesteps, 41 features)\n",
    "sequences_a[0].shape, sequences_c[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n"
     ]
    }
   ],
   "source": [
    "# Check if all sequences have the same length\n",
    "lengths = [len(seq) for seq in sequences_a]\n",
    "print(len(lengths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It makes sense, we do not have complete 49 measurements for each patient, they might be less"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need to pad the sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4000, 49, 40]),\n",
       " torch.Size([4000]),\n",
       " torch.Size([4000, 49, 40]),\n",
       " torch.Size([4000]))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "padded_sequences_a = pad_sequence(sequences_a, batch_first=True)\n",
    "padded_sequences_c = pad_sequence(sequences_c, batch_first=True)\n",
    "\n",
    "train_X = padded_sequences_a\n",
    "train_y = torch.tensor(death_a[\"In-hospital_death\"])\n",
    "\n",
    "test_X = padded_sequences_c\n",
    "test_y = torch.tensor(death_c[\"In-hospital_death\"])\n",
    "\n",
    "train_X.shape, train_y.shape, test_X.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create DataLoaders (very useful for NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_dataset = TensorDataset(train_X, train_y)\n",
    "test_dataset = TensorDataset(test_X, test_y)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Loss: 0.4836\n",
      "Epoch 2/10 | Loss: 0.3410\n",
      "Epoch 3/10 | Loss: 0.3102\n",
      "Epoch 4/10 | Loss: 0.2930\n",
      "Epoch 5/10 | Loss: 0.2774\n",
      "Epoch 6/10 | Loss: 0.2672\n",
      "Epoch 7/10 | Loss: 0.2530\n",
      "Epoch 8/10 | Loss: 0.2472\n",
      "Epoch 9/10 | Loss: 0.2378\n",
      "Epoch 10/10 | Loss: 0.2141\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = LSTM_Model(\n",
    "    input_size=train_X.shape[2],  # 40\n",
    "    hidden_size=64,\n",
    "    num_layers=1,\n",
    "    num_classes=1,\n",
    "    dropout=0.0\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "\n",
    "        # Sanity check shapes\n",
    "        assert outputs.shape == batch_y.shape, f\"Shape mismatch: {outputs.shape} vs {batch_y.shape}\"\n",
    "\n",
    "        # Convert to float\n",
    "        batch_y = batch_y.float()\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} | Loss: {running_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Test Metrics:\n",
      "âœ… ROC AUC:  0.814\n",
      "âœ… AUPRC:    0.450\n",
      "âœ… Accuracy: 0.860\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score\n",
    "import torch.nn.functional as F\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_y in test_loader:\n",
    "        batch_X = batch_X.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        logits = model(batch_X)\n",
    "        probs = torch.sigmoid(logits)  # convert to [0, 1]\n",
    "\n",
    "        all_preds.extend(probs.cpu().numpy())\n",
    "        all_labels.extend(batch_y.cpu().numpy())\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "# Thresholding for accuracy (default: 0.5)\n",
    "binary_preds = (all_preds >= 0.5).astype(int)\n",
    "\n",
    "# Metrics\n",
    "roc_auc = roc_auc_score(all_labels, all_preds)\n",
    "auprc = average_precision_score(all_labels, all_preds)\n",
    "accuracy = accuracy_score(all_labels, binary_preds)\n",
    "\n",
    "print(f\"\\nðŸ“Š Test Metrics:\")\n",
    "print(f\"âœ… ROC AUC:  {roc_auc:.3f}\")\n",
    "print(f\"âœ… AUPRC:    {auprc:.3f}\")\n",
    "print(f\"âœ… Accuracy: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt 1 - Mean Pooling in LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Model_Pooling(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=64, num_layers=2, num_classes=1, dropout=0.3):\n",
    "        super(LSTM_Model_Pooling, self).__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,       # 41 features per time step\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, seq_len, input_size)\n",
    "        out, _ = self.lstm(x)           # out: (batch_size, seq_len, hidden_size)\n",
    "        out = out.mean(dim=1)           # Pooling: (batch_size, hidden_size)   \n",
    "        out = self.fc(out)              # (batch_size, num_classes)\n",
    "        return out.squeeze()            # (batch_size,) for BCEWithLogitsLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Loss: 0.4719\n",
      "Epoch 2/10 | Loss: 0.3476\n",
      "Epoch 3/10 | Loss: 0.3278\n",
      "Epoch 4/10 | Loss: 0.3129\n",
      "Epoch 5/10 | Loss: 0.3036\n",
      "Epoch 6/10 | Loss: 0.3003\n",
      "Epoch 7/10 | Loss: 0.2832\n",
      "Epoch 8/10 | Loss: 0.2678\n",
      "Epoch 9/10 | Loss: 0.2595\n",
      "Epoch 10/10 | Loss: 0.2517\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = LSTM_Model_Pooling(\n",
    "    input_size=train_X.shape[2],  # 40\n",
    "    hidden_size=64,\n",
    "    num_layers=1,\n",
    "    num_classes=1,\n",
    "    dropout=0.0\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "\n",
    "        # Sanity check shapes\n",
    "        assert outputs.shape == batch_y.shape, f\"Shape mismatch: {outputs.shape} vs {batch_y.shape}\"\n",
    "\n",
    "        # Convert to float\n",
    "        batch_y = batch_y.float()\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} | Loss: {running_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Test Metrics:\n",
      "âœ… ROC AUC:  0.809\n",
      "âœ… AUPRC:    0.443\n",
      "âœ… Accuracy: 0.855\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score\n",
    "import torch.nn.functional as F\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_y in test_loader:\n",
    "        batch_X = batch_X.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        logits = model(batch_X)\n",
    "        probs = torch.sigmoid(logits)  # convert to [0, 1]\n",
    "\n",
    "        all_preds.extend(probs.cpu().numpy())\n",
    "        all_labels.extend(batch_y.cpu().numpy())\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "# Thresholding for accuracy (default: 0.5)\n",
    "binary_preds = (all_preds >= 0.5).astype(int)\n",
    "\n",
    "# Metrics\n",
    "roc_auc = roc_auc_score(all_labels, all_preds)\n",
    "auprc = average_precision_score(all_labels, all_preds)\n",
    "accuracy = accuracy_score(all_labels, binary_preds)\n",
    "\n",
    "print(f\"\\nðŸ“Š Test Metrics:\")\n",
    "print(f\"âœ… ROC AUC:  {roc_auc:.3f}\")\n",
    "print(f\"âœ… AUPRC:    {auprc:.3f}\")\n",
    "print(f\"âœ… Accuracy: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 2 - Max Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bidirection LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Model_Bi(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=64, num_layers=2, num_classes=1, dropout=0.3):\n",
    "        super(LSTM_Model_Bi, self).__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,       # 41 features per time step\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_classes) # *2 for bidirectional\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, seq_len, input_size)\n",
    "        out, _ = self.lstm(x)           # out: (batch_size, seq_len, hidden_size)\n",
    "        out = out.max(dim=1)[0]\n",
    "        out = self.fc(out)              # (batch_size, num_classes)\n",
    "        return out.squeeze()            # (batch_size,) for BCEWithLogitsLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Loss: 0.5216\n",
      "Epoch 2/10 | Loss: 0.3950\n",
      "Epoch 3/10 | Loss: 0.3776\n",
      "Epoch 4/10 | Loss: 0.3619\n",
      "Epoch 5/10 | Loss: 0.3439\n",
      "Epoch 6/10 | Loss: 0.3311\n",
      "Epoch 7/10 | Loss: 0.3159\n",
      "Epoch 8/10 | Loss: 0.3054\n",
      "Epoch 9/10 | Loss: 0.2938\n",
      "Epoch 10/10 | Loss: 0.2840\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = LSTM_Model_Bi(\n",
    "    input_size=train_X.shape[2],  # 41\n",
    "    hidden_size=16,\n",
    "    num_layers=1,\n",
    "    num_classes=1,\n",
    "    dropout=0.0\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "\n",
    "        # Sanity check shapes\n",
    "        assert outputs.shape == batch_y.shape, f\"Shape mismatch: {outputs.shape} vs {batch_y.shape}\"\n",
    "\n",
    "        # Convert to float\n",
    "        batch_y = batch_y.float()\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} | Loss: {running_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Test Metrics:\n",
      "âœ… ROC AUC:  0.805\n",
      "âœ… AUPRC:    0.432\n",
      "âœ… Accuracy: 0.858\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score\n",
    "import torch.nn.functional as F\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_y in test_loader:\n",
    "        batch_X = batch_X.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        logits = model(batch_X)\n",
    "        probs = torch.sigmoid(logits)  # convert to [0, 1]\n",
    "\n",
    "        all_preds.extend(probs.cpu().numpy())\n",
    "        all_labels.extend(batch_y.cpu().numpy())\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "# Thresholding for accuracy (default: 0.5)\n",
    "binary_preds = (all_preds >= 0.5).astype(int)\n",
    "\n",
    "# Metrics\n",
    "roc_auc = roc_auc_score(all_labels, all_preds)\n",
    "auprc = average_precision_score(all_labels, all_preds)\n",
    "accuracy = accuracy_score(all_labels, binary_preds)\n",
    "\n",
    "print(f\"\\nðŸ“Š Test Metrics:\")\n",
    "print(f\"âœ… ROC AUC:  {roc_auc:.3f}\")\n",
    "print(f\"âœ… AUPRC:    {auprc:.3f}\")\n",
    "print(f\"âœ… Accuracy: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to use MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(183416, 43)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>RecordID</th>\n",
       "      <th>Age</th>\n",
       "      <th>BUN</th>\n",
       "      <th>Creatinine</th>\n",
       "      <th>GCS</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>HCO3</th>\n",
       "      <th>HCT</th>\n",
       "      <th>...</th>\n",
       "      <th>PaCO2</th>\n",
       "      <th>PaO2</th>\n",
       "      <th>pH</th>\n",
       "      <th>DiasABP</th>\n",
       "      <th>MAP</th>\n",
       "      <th>SaO2</th>\n",
       "      <th>SysABP</th>\n",
       "      <th>Lactate</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>TroponinI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-03-10 00:00:00</td>\n",
       "      <td>132539.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>36.40</td>\n",
       "      <td>...</td>\n",
       "      <td>36.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>7.48</td>\n",
       "      <td>47.0</td>\n",
       "      <td>87.00</td>\n",
       "      <td>98.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>3.60</td>\n",
       "      <td>152.0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-03-10 01:00:00</td>\n",
       "      <td>132539.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>29.60</td>\n",
       "      <td>...</td>\n",
       "      <td>43.0</td>\n",
       "      <td>385.0</td>\n",
       "      <td>7.40</td>\n",
       "      <td>50.0</td>\n",
       "      <td>96.50</td>\n",
       "      <td>98.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>3.25</td>\n",
       "      <td>160.0</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-03-10 02:00:00</td>\n",
       "      <td>132539.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>29.80</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>7.32</td>\n",
       "      <td>69.5</td>\n",
       "      <td>55.00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>6.20</td>\n",
       "      <td>158.0</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-03-10 03:00:00</td>\n",
       "      <td>132539.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>26.75</td>\n",
       "      <td>...</td>\n",
       "      <td>62.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>7.36</td>\n",
       "      <td>47.0</td>\n",
       "      <td>85.00</td>\n",
       "      <td>98.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>6.40</td>\n",
       "      <td>169.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-03-10 04:00:00</td>\n",
       "      <td>132539.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>33.70</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>7.47</td>\n",
       "      <td>78.0</td>\n",
       "      <td>85.75</td>\n",
       "      <td>99.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>2.30</td>\n",
       "      <td>111.0</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Time  RecordID   Age   BUN  Creatinine   GCS  Gender  \\\n",
       "0 2025-03-10 00:00:00  132539.0  54.0  15.0         2.9  15.0     0.0   \n",
       "1 2025-03-10 01:00:00  132539.0  54.0  17.0         1.0  15.0     0.0   \n",
       "2 2025-03-10 02:00:00  132539.0  54.0  20.0         0.8  15.0     0.0   \n",
       "3 2025-03-10 03:00:00  132539.0  54.0   8.0         0.7  15.0     0.0   \n",
       "4 2025-03-10 04:00:00  132539.0  54.0   9.0         0.3  15.0     0.0   \n",
       "\n",
       "   Glucose  HCO3    HCT  ...  PaCO2   PaO2    pH  DiasABP    MAP  SaO2  \\\n",
       "0     89.0  23.0  36.40  ...   36.0  258.0  7.48     47.0  87.00  98.0   \n",
       "1    147.0  23.0  29.60  ...   43.0  385.0  7.40     50.0  96.50  98.0   \n",
       "2    210.0  27.0  29.80  ...   35.0  195.0  7.32     69.5  55.00  97.0   \n",
       "3     75.0  21.0  26.75  ...   62.0  285.0  7.36     47.0  85.00  98.0   \n",
       "4    154.0  20.0  33.70  ...   45.0  431.0  7.47     78.0  85.75  99.0   \n",
       "\n",
       "   SysABP  Lactate  Cholesterol  TroponinI  \n",
       "0    89.0     3.60        152.0        3.5  \n",
       "1   135.0     3.25        160.0        0.9  \n",
       "2   130.0     6.20        158.0        1.1  \n",
       "3   105.0     6.40        169.0       31.0  \n",
       "4   136.0     2.30        111.0        7.4  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data before being scaled\n",
    "sets_dict_2 = {}\n",
    "sets = [\"a\", \"b\", \"c\"]\n",
    "\n",
    "for set_name in sets:\n",
    "    directory = PROCESSED_DATA_DIR / f\"set_{set_name}_to_scale.parquet\"\n",
    "    temp_set = pd.read_parquet(directory)\n",
    "    sets_dict_2[f\"set_{set_name}\"] = temp_set\n",
    "\n",
    "print(sets_dict_2[\"set_a\"].shape)\n",
    "sets_dict_2[\"set_a\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103094.6\n"
     ]
    }
   ],
   "source": [
    "# Cbeck Gender\n",
    "print(sets_dict_2[\"set_a\"][\"Gender\"].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>RecordID</th>\n",
       "      <th>Age</th>\n",
       "      <th>BUN</th>\n",
       "      <th>Creatinine</th>\n",
       "      <th>GCS</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>HCO3</th>\n",
       "      <th>HCT</th>\n",
       "      <th>...</th>\n",
       "      <th>PaCO2</th>\n",
       "      <th>PaO2</th>\n",
       "      <th>pH</th>\n",
       "      <th>DiasABP</th>\n",
       "      <th>MAP</th>\n",
       "      <th>SaO2</th>\n",
       "      <th>SysABP</th>\n",
       "      <th>Lactate</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>TroponinI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-03-10 00:00:00</td>\n",
       "      <td>132539.0</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.076142</td>\n",
       "      <td>0.127273</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.069726</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.518939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280899</td>\n",
       "      <td>0.495833</td>\n",
       "      <td>0.034839</td>\n",
       "      <td>0.175373</td>\n",
       "      <td>0.294915</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.323636</td>\n",
       "      <td>0.113793</td>\n",
       "      <td>0.410596</td>\n",
       "      <td>0.065440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-03-10 01:00:00</td>\n",
       "      <td>132539.0</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.086294</td>\n",
       "      <td>0.040909</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.120918</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.390152</td>\n",
       "      <td>...</td>\n",
       "      <td>0.359551</td>\n",
       "      <td>0.760417</td>\n",
       "      <td>0.034409</td>\n",
       "      <td>0.186567</td>\n",
       "      <td>0.327119</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.490909</td>\n",
       "      <td>0.101724</td>\n",
       "      <td>0.437086</td>\n",
       "      <td>0.012270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-03-10 02:00:00</td>\n",
       "      <td>132539.0</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.101523</td>\n",
       "      <td>0.031818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.176523</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.269663</td>\n",
       "      <td>0.364583</td>\n",
       "      <td>0.033978</td>\n",
       "      <td>0.259328</td>\n",
       "      <td>0.186441</td>\n",
       "      <td>0.959459</td>\n",
       "      <td>0.472727</td>\n",
       "      <td>0.203448</td>\n",
       "      <td>0.430464</td>\n",
       "      <td>0.016360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-03-10 03:00:00</td>\n",
       "      <td>132539.0</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.040609</td>\n",
       "      <td>0.027273</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057370</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.336174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573034</td>\n",
       "      <td>0.552083</td>\n",
       "      <td>0.034194</td>\n",
       "      <td>0.175373</td>\n",
       "      <td>0.288136</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.381818</td>\n",
       "      <td>0.210345</td>\n",
       "      <td>0.466887</td>\n",
       "      <td>0.627812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-03-10 04:00:00</td>\n",
       "      <td>132539.0</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.045685</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.127096</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.467803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382022</td>\n",
       "      <td>0.856250</td>\n",
       "      <td>0.034785</td>\n",
       "      <td>0.291045</td>\n",
       "      <td>0.290678</td>\n",
       "      <td>0.986486</td>\n",
       "      <td>0.494545</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.274834</td>\n",
       "      <td>0.145194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Time  RecordID   Age       BUN  Creatinine  GCS  Gender  \\\n",
       "0 2025-03-10 00:00:00  132539.0  0.52  0.076142    0.127273  1.0     0.0   \n",
       "1 2025-03-10 01:00:00  132539.0  0.52  0.086294    0.040909  1.0     0.0   \n",
       "2 2025-03-10 02:00:00  132539.0  0.52  0.101523    0.031818  1.0     0.0   \n",
       "3 2025-03-10 03:00:00  132539.0  0.52  0.040609    0.027273  1.0     0.0   \n",
       "4 2025-03-10 04:00:00  132539.0  0.52  0.045685    0.009091  1.0     0.0   \n",
       "\n",
       "    Glucose      HCO3       HCT  ...     PaCO2      PaO2        pH   DiasABP  \\\n",
       "0  0.069726  0.400000  0.518939  ...  0.280899  0.495833  0.034839  0.175373   \n",
       "1  0.120918  0.400000  0.390152  ...  0.359551  0.760417  0.034409  0.186567   \n",
       "2  0.176523  0.488889  0.393939  ...  0.269663  0.364583  0.033978  0.259328   \n",
       "3  0.057370  0.355556  0.336174  ...  0.573034  0.552083  0.034194  0.175373   \n",
       "4  0.127096  0.333333  0.467803  ...  0.382022  0.856250  0.034785  0.291045   \n",
       "\n",
       "        MAP      SaO2    SysABP   Lactate  Cholesterol  TroponinI  \n",
       "0  0.294915  0.972973  0.323636  0.113793     0.410596   0.065440  \n",
       "1  0.327119  0.972973  0.490909  0.101724     0.437086   0.012270  \n",
       "2  0.186441  0.959459  0.472727  0.203448     0.430464   0.016360  \n",
       "3  0.288136  0.972973  0.381818  0.210345     0.466887   0.627812  \n",
       "4  0.290678  0.986486  0.494545  0.068966     0.274834   0.145194  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now use the MinMaxScaler on the selected columns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "selected_columns = [col for col in sets_dict_2[\"set_a\"].columns if col not in [\"RecordID\", \"Time\"]]\n",
    "sets_dict_2[\"set_a\"][selected_columns] = scaler.fit_transform(sets_dict_2[\"set_a\"][selected_columns])\n",
    "sets_dict_2[\"set_b\"][selected_columns] = scaler.transform(sets_dict_2[\"set_b\"][selected_columns])\n",
    "sets_dict_2[\"set_c\"][selected_columns] = scaler.transform(sets_dict_2[\"set_c\"][selected_columns])\n",
    "\n",
    "# Check if the scaling was successful\n",
    "sets_dict_2[\"set_a\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.  1.  0.5 0.7 0.4]\n"
     ]
    }
   ],
   "source": [
    "# Check Gender column values\n",
    "print(sets_dict_2[\"set_a\"][\"Gender\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kinda weird isn't it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Check if ICUType is present\n",
    "print(True if \"ICUType\" in sets_dict_2[\"set_a\"].columns else False)\n",
    "if \"ICUType\" in sets_dict_2[\"set_a\"].columns:\n",
    "    sets_dict_2[\"set_a\"] = sets_dict_2[\"set_a\"].drop(columns=[\"ICUType\"])\n",
    "\n",
    "if \"ICUType\" in sets_dict_2[\"set_b\"].columns:\n",
    "    sets_dict_2[\"set_b\"] = sets_dict_2[\"set_b\"].drop(columns=[\"ICUType\"])\n",
    "\n",
    "if \"ICUType\" in sets_dict_2[\"set_c\"].columns:\n",
    "    sets_dict_2[\"set_c\"] = sets_dict_2[\"set_c\"].drop(columns=[\"ICUType\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([48, 40]), torch.Size([47, 40]))"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only convert sets A and C\n",
    "\n",
    "# Convert the sets to PyTorch tensors\n",
    "features_cols = [col for col in sets_dict_2[\"set_a\"].columns if col not in [\"RecordID\", \"Time\"]]\n",
    "\n",
    "sequences_a_2 = []\n",
    "sequences_c_2 = []\n",
    "set_a = sets_dict_2[\"set_a\"]\n",
    "set_c = sets_dict_2[\"set_c\"]\n",
    "for record_id, group in set_a.groupby(\"RecordID\"):\n",
    "    seq = group[features_cols].to_numpy(dtype=np.float32)\n",
    "    sequences_a_2.append(torch.tensor(seq))\n",
    "\n",
    "for record_id, group in set_c.groupby(\"RecordID\"):\n",
    "    seq = group[features_cols].to_numpy(dtype=np.float32)\n",
    "    sequences_c_2.append(torch.tensor(seq))\n",
    "\n",
    "# Now sequences_a_2 is a list of PyTorch tensors, of shape (48, 41) each (48 timesteps, 41 features)\n",
    "sequences_a_2[0].shape, sequences_c_2[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4000, 49, 40]),\n",
       " torch.Size([4000]),\n",
       " torch.Size([4000, 49, 40]),\n",
       " torch.Size([4000]))"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "padded_sequences_a = pad_sequence(sequences_a_2, batch_first=True)\n",
    "padded_sequences_c = pad_sequence(sequences_c_2, batch_first=True)\n",
    "\n",
    "train_X = padded_sequences_a\n",
    "train_y = torch.tensor(death_a[\"In-hospital_death\"])\n",
    "\n",
    "test_X = padded_sequences_c\n",
    "test_y = torch.tensor(death_c[\"In-hospital_death\"])\n",
    "\n",
    "train_X.shape, train_y.shape, test_X.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Loss: 0.4475\n",
      "Epoch 2/10 | Loss: 0.3374\n",
      "Epoch 3/10 | Loss: 0.3134\n",
      "Epoch 4/10 | Loss: 0.2995\n",
      "Epoch 5/10 | Loss: 0.2857\n",
      "Epoch 6/10 | Loss: 0.2710\n",
      "Epoch 7/10 | Loss: 0.2620\n",
      "Epoch 8/10 | Loss: 0.2400\n",
      "Epoch 9/10 | Loss: 0.2282\n",
      "Epoch 10/10 | Loss: 0.2116\n"
     ]
    }
   ],
   "source": [
    "# Feed this dataframe into the LSTM\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = LSTM_Model(\n",
    "    input_size=train_X.shape[2],  # 40\n",
    "    hidden_size=64,\n",
    "    num_layers=1,\n",
    "    num_classes=1,\n",
    "    dropout=0.0\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "\n",
    "        # Sanity check shapes\n",
    "        assert outputs.shape == batch_y.shape, f\"Shape mismatch: {outputs.shape} vs {batch_y.shape}\"\n",
    "\n",
    "        # Convert to float\n",
    "        batch_y = batch_y.float()\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} | Loss: {running_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Test Metrics:\n",
      "âœ… ROC AUC:  0.778\n",
      "âœ… AUPRC:    0.406\n",
      "âœ… Accuracy: 0.857\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score\n",
    "import torch.nn.functional as F\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_y in test_loader:\n",
    "        batch_X = batch_X.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        logits = model(batch_X)\n",
    "        probs = torch.sigmoid(logits)  # convert to [0, 1]\n",
    "\n",
    "        all_preds.extend(probs.cpu().numpy())\n",
    "        all_labels.extend(batch_y.cpu().numpy())\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "# Thresholding for accuracy (default: 0.5)\n",
    "binary_preds = (all_preds >= 0.5).astype(int)\n",
    "\n",
    "# Metrics\n",
    "roc_auc = roc_auc_score(all_labels, all_preds)\n",
    "auprc = average_precision_score(all_labels, all_preds)\n",
    "accuracy = accuracy_score(all_labels, binary_preds)\n",
    "\n",
    "print(f\"\\nðŸ“Š Test Metrics:\")\n",
    "print(f\"âœ… ROC AUC:  {roc_auc:.3f}\")\n",
    "print(f\"âœ… AUPRC:    {auprc:.3f}\")\n",
    "print(f\"âœ… Accuracy: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TUM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
