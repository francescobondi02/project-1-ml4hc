{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfomers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-24 11:25:10.986\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproject_1.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mPROJ_ROOT path is: /Users/francescobondi/Desktop/stuff/ETH/FS25/ML for Healthcare/project-1-ml4hc\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from project_1.config import PROJ_ROOT, PROCESSED_DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 2)\n",
      "(183416, 43)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordID</th>\n",
       "      <th>Time</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Age</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>DiasABP</th>\n",
       "      <th>HCO3</th>\n",
       "      <th>...</th>\n",
       "      <th>Urine</th>\n",
       "      <th>WBC</th>\n",
       "      <th>pH</th>\n",
       "      <th>MechVent</th>\n",
       "      <th>TroponinT</th>\n",
       "      <th>ALP</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AST</th>\n",
       "      <th>Bilirubin</th>\n",
       "      <th>TroponinI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>132539.0</td>\n",
       "      <td>2025-03-10 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.950526</td>\n",
       "      <td>-0.23008</td>\n",
       "      <td>-0.596332</td>\n",
       "      <td>1.671639</td>\n",
       "      <td>-0.013487</td>\n",
       "      <td>-0.832594</td>\n",
       "      <td>-0.109176</td>\n",
       "      <td>...</td>\n",
       "      <td>11.571429</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>1.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.923077</td>\n",
       "      <td>0.132075</td>\n",
       "      <td>-0.176471</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>1.545455</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132539.0</td>\n",
       "      <td>2025-03-10 01:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.950526</td>\n",
       "      <td>-0.23008</td>\n",
       "      <td>-0.596332</td>\n",
       "      <td>1.967793</td>\n",
       "      <td>0.172112</td>\n",
       "      <td>-0.608431</td>\n",
       "      <td>-0.109176</td>\n",
       "      <td>...</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>-0.420290</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.246154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.294118</td>\n",
       "      <td>0.436620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.126984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>132539.0</td>\n",
       "      <td>2025-03-10 02:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.950526</td>\n",
       "      <td>-0.23008</td>\n",
       "      <td>-0.596332</td>\n",
       "      <td>-1.734132</td>\n",
       "      <td>0.125712</td>\n",
       "      <td>0.848629</td>\n",
       "      <td>0.830987</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.357143</td>\n",
       "      <td>-0.014493</td>\n",
       "      <td>-0.875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.773585</td>\n",
       "      <td>-0.205882</td>\n",
       "      <td>-0.380282</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>-0.095238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132539.0</td>\n",
       "      <td>2025-03-10 03:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.950526</td>\n",
       "      <td>-0.23008</td>\n",
       "      <td>-0.596332</td>\n",
       "      <td>1.523562</td>\n",
       "      <td>0.380910</td>\n",
       "      <td>-0.832594</td>\n",
       "      <td>-0.579257</td>\n",
       "      <td>...</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.188406</td>\n",
       "      <td>-0.375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.215385</td>\n",
       "      <td>-0.698113</td>\n",
       "      <td>-0.588235</td>\n",
       "      <td>1.126761</td>\n",
       "      <td>-0.181818</td>\n",
       "      <td>4.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132539.0</td>\n",
       "      <td>2025-03-10 04:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.950526</td>\n",
       "      <td>-0.23008</td>\n",
       "      <td>-0.596332</td>\n",
       "      <td>0.487023</td>\n",
       "      <td>-0.964680</td>\n",
       "      <td>1.483758</td>\n",
       "      <td>-0.814297</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.142857</td>\n",
       "      <td>-1.144928</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.738462</td>\n",
       "      <td>-0.490566</td>\n",
       "      <td>-0.558824</td>\n",
       "      <td>-0.225352</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RecordID                Time  Gender    Height   Weight       Age  \\\n",
       "0  132539.0 2025-03-10 00:00:00     0.0 -0.950526 -0.23008 -0.596332   \n",
       "1  132539.0 2025-03-10 01:00:00     0.0 -0.950526 -0.23008 -0.596332   \n",
       "2  132539.0 2025-03-10 02:00:00     0.0 -0.950526 -0.23008 -0.596332   \n",
       "3  132539.0 2025-03-10 03:00:00     0.0 -0.950526 -0.23008 -0.596332   \n",
       "4  132539.0 2025-03-10 04:00:00     0.0 -0.950526 -0.23008 -0.596332   \n",
       "\n",
       "    Albumin  Cholesterol   DiasABP      HCO3  ...      Urine       WBC     pH  \\\n",
       "0  1.671639    -0.013487 -0.832594 -0.109176  ...  11.571429  0.753623  1.125   \n",
       "1  1.967793     0.172112 -0.608431 -0.109176  ...   2.857143 -0.420290  0.125   \n",
       "2 -1.734132     0.125712  0.848629  0.830987  ...  -0.357143 -0.014493 -0.875   \n",
       "3  1.523562     0.380910 -0.832594 -0.579257  ...   0.642857  0.188406 -0.375   \n",
       "4  0.487023    -0.964680  1.483758 -0.814297  ...  -0.142857 -1.144928  1.000   \n",
       "\n",
       "   MechVent  TroponinT       ALP       ALT       AST  Bilirubin  TroponinI  \n",
       "0       0.0   1.923077  0.132075 -0.176471  0.450704   1.545455   0.285714  \n",
       "1       0.0  -0.246154  0.000000 -0.294118  0.436620   0.000000  -0.126984  \n",
       "2       0.0   0.000000  0.773585 -0.205882 -0.380282   0.181818  -0.095238  \n",
       "3       0.0   0.215385 -0.698113 -0.588235  1.126761  -0.181818   4.650794  \n",
       "4       0.0   2.738462 -0.490566 -0.558824 -0.225352   0.363636   0.904762  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data from Parquet files\n",
    "sets_dict = {}\n",
    "sets = [\"a\", \"b\", \"c\"]\n",
    "\n",
    "for set_name in sets:\n",
    "    directory = PROCESSED_DATA_DIR / f\"set_{set_name}_final.parquet\"\n",
    "    temp_set = pd.read_parquet(directory)\n",
    "    sets_dict[f\"set_{set_name}\"] = temp_set\n",
    "\n",
    "# Define file names\n",
    "file_names = [\"Outcomes-a.txt\", \"Outcomes-b.txt\", \"Outcomes-c.txt\"]\n",
    "\n",
    "# Directory path\n",
    "base_path = PROJ_ROOT / \"data\" / \"data_1\" / \"predicting-mortality-of-icu-patients-the-physionet-computing-in-cardiology-challenge-2012-1.0.0\"\n",
    "\n",
    "# Read files into DataFrames containing all variables\n",
    "outcomes_a, outcomes_b, outcomes_c = [pd.read_csv(base_path / name) for name in file_names]\n",
    "\n",
    "# Extract only the \"RecordID\" and \"In-hospital_death\" column into separate DataFrames\n",
    "death_a, death_b, death_c = [df[[\"RecordID\", \"In-hospital_death\"]] for df in [outcomes_a, outcomes_b, outcomes_c]]\n",
    "print(death_a.shape)\n",
    "\n",
    "#CHECK for missing values in the outcome data\n",
    "\"\"\"print(death_a.isnull().sum())\n",
    "print(death_b.isnull().sum())\n",
    "print(death_c.isnull().sum())\"\"\"\n",
    "# Assure the loading was correct\n",
    "print(sets_dict[\"set_a\"].shape)\n",
    "sets_dict[\"set_a\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove ICUType from the data\n",
    "for set_name in sets:\n",
    "    if \"ICUType\" in sets_dict[f\"set_{set_name}\"].columns:\n",
    "        sets_dict[f\"set_{set_name}\"] = sets_dict[f\"set_{set_name}\"].drop(columns=[\"ICUType\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([48, 40]), torch.Size([47, 40]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only convert sets A and C\n",
    "\n",
    "# Convert the sets to PyTorch tensors\n",
    "features_cols = [col for col in sets_dict[\"set_a\"].columns if col not in [\"RecordID\", \"Time\"]]\n",
    "\n",
    "sequences_a = []\n",
    "sequences_c = []\n",
    "set_a = sets_dict[\"set_a\"]\n",
    "set_c = sets_dict[\"set_c\"]\n",
    "for record_id, group in set_a.groupby(\"RecordID\"):\n",
    "    seq = group[features_cols].to_numpy(dtype=np.float32)\n",
    "    sequences_a.append(torch.tensor(seq))\n",
    "\n",
    "for record_id, group in set_c.groupby(\"RecordID\"):\n",
    "    seq = group[features_cols].to_numpy(dtype=np.float32)\n",
    "    sequences_c.append(torch.tensor(seq))\n",
    "\n",
    "# Now sequences_a is a list of PyTorch tensors, of shape (48, 41) each (48 timesteps, 41 features)\n",
    "sequences_a[0].shape, sequences_c[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4000, 49, 40]),\n",
       " torch.Size([4000]),\n",
       " torch.Size([4000, 49, 40]),\n",
       " torch.Size([4000]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "padded_sequences_a = pad_sequence(sequences_a, batch_first=True)\n",
    "padded_sequences_c = pad_sequence(sequences_c, batch_first=True)\n",
    "\n",
    "train_X = padded_sequences_a\n",
    "train_y = torch.tensor(death_a[\"In-hospital_death\"])\n",
    "\n",
    "test_X = padded_sequences_c\n",
    "test_y = torch.tensor(death_c[\"In-hospital_death\"])\n",
    "\n",
    "train_X.shape, train_y.shape, test_X.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_dataset = TensorDataset(train_X, train_y)\n",
    "test_dataset = TensorDataset(test_X, test_y)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Implementation of Transformers (and Positional Encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, input_size, num_classes=1, nhead=4, num_layers=2, dim_feedforward=128, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "\n",
    "        # Project input features to model dimension\n",
    "        self.embedding = nn.Linear(input_size, dim_feedforward)\n",
    "\n",
    "        # Positional Encoding\n",
    "        self.pos_encoder = PositionalEncoding(dim_feedforward, dropout)\n",
    "\n",
    "        # Transformer Encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=dim_feedforward,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward * 2,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        # Final classifier\n",
    "        self.fc = nn.Linear(dim_feedforward, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_len, input_size)\n",
    "        x = self.embedding(x)                # (batch, seq_len, d_model)\n",
    "        x = self.pos_encoder(x)\n",
    "        x = self.transformer_encoder(x)      # (batch, seq_len, d_model)\n",
    "\n",
    "        x = x.mean(dim=1)                    # mean pooling over time\n",
    "        out = self.fc(x).squeeze()           # (batch,)\n",
    "        return out\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=500):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)  # (max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(torch.log(torch.tensor(10000.0)) / d_model))\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)  # (1, max_len, d_model)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains NaNs: tensor(False)\n",
      "contains Infs: tensor(False)\n"
     ]
    }
   ],
   "source": [
    "print(\"contains NaNs:\", torch.isnan(train_X).any())\n",
    "print(\"contains Infs:\", torch.isinf(train_X).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francescobondi/anaconda3/envs/TUM/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Loss: 0.3811\n",
      "Epoch 2/10 | Loss: 0.3354\n",
      "Epoch 3/10 | Loss: 0.3307\n",
      "Epoch 4/10 | Loss: 0.3244\n",
      "Epoch 5/10 | Loss: 0.3157\n",
      "Epoch 6/10 | Loss: 0.3128\n",
      "Epoch 7/10 | Loss: 0.3043\n",
      "Epoch 8/10 | Loss: 0.3000\n",
      "Epoch 9/10 | Loss: 0.2949\n",
      "Epoch 10/10 | Loss: 0.2793\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = TransformerClassifier(input_size=train_X.shape[2]).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "\n",
    "        # Sanity check shapes\n",
    "        assert outputs.shape == batch_y.shape, f\"Shape mismatch: {outputs.shape} vs {batch_y.shape}\"\n",
    "\n",
    "        # Convert to float\n",
    "        batch_y = batch_y.float()\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} | Loss: {running_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Evaluation Metrics for Transformer:\n",
      "ðŸ”¹ ROC AUC:  0.823\n",
      "ðŸ”¹ AUPRC:    0.465\n",
      "ðŸ”¹ Accuracy: 0.856\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_y in test_loader:\n",
    "        batch_X = batch_X.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        logits = model(batch_X)  # output is raw score (logits)\n",
    "        probs = torch.sigmoid(logits)  # convert to [0, 1]\n",
    "\n",
    "        all_preds.extend(probs.cpu().numpy())\n",
    "        all_labels.extend(batch_y.cpu().numpy())\n",
    "\n",
    "# Convert to numpy arrays\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "# Thresholding at 0.5 for classification\n",
    "binary_preds = (all_preds >= 0.5).astype(int)\n",
    "\n",
    "# Metrics\n",
    "roc_auc = roc_auc_score(all_labels, all_preds)\n",
    "auprc = average_precision_score(all_labels, all_preds)\n",
    "accuracy = accuracy_score(all_labels, binary_preds)\n",
    "\n",
    "# Report\n",
    "print(f\"\\nðŸ“Š Evaluation Metrics for Transformer:\")\n",
    "print(f\"ðŸ”¹ ROC AUC:  {roc_auc:.3f}\")\n",
    "print(f\"ðŸ”¹ AUPRC:    {auprc:.3f}\")\n",
    "print(f\"ðŸ”¹ Accuracy: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2.3 - Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(183416, 43)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordID</th>\n",
       "      <th>Time</th>\n",
       "      <th>Age</th>\n",
       "      <th>BUN</th>\n",
       "      <th>Creatinine</th>\n",
       "      <th>GCS</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>HCO3</th>\n",
       "      <th>HCT</th>\n",
       "      <th>...</th>\n",
       "      <th>PaCO2</th>\n",
       "      <th>PaO2</th>\n",
       "      <th>pH</th>\n",
       "      <th>DiasABP</th>\n",
       "      <th>MAP</th>\n",
       "      <th>SaO2</th>\n",
       "      <th>SysABP</th>\n",
       "      <th>Lactate</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>TroponinI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>132539.0</td>\n",
       "      <td>2025-03-10 00:00:00</td>\n",
       "      <td>54.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132539.0</td>\n",
       "      <td>2025-03-10 01:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>132539.0</td>\n",
       "      <td>2025-03-10 02:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132539.0</td>\n",
       "      <td>2025-03-10 03:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132539.0</td>\n",
       "      <td>2025-03-10 04:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.7</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RecordID                Time   Age  BUN  Creatinine   GCS  Gender  Glucose  \\\n",
       "0  132539.0 2025-03-10 00:00:00  54.0  NaN         NaN   NaN     0.0      NaN   \n",
       "1  132539.0 2025-03-10 01:00:00   NaN  NaN         NaN  15.0     NaN      NaN   \n",
       "2  132539.0 2025-03-10 02:00:00   NaN  NaN         NaN   NaN     NaN      NaN   \n",
       "3  132539.0 2025-03-10 03:00:00   NaN  NaN         NaN   NaN     NaN      NaN   \n",
       "4  132539.0 2025-03-10 04:00:00   NaN  NaN         NaN  15.0     NaN      NaN   \n",
       "\n",
       "   HCO3   HCT  ...  PaCO2  PaO2  pH  DiasABP  MAP  SaO2  SysABP  Lactate  \\\n",
       "0   NaN   NaN  ...    NaN   NaN NaN      NaN  NaN   NaN     NaN      NaN   \n",
       "1   NaN   NaN  ...    NaN   NaN NaN      NaN  NaN   NaN     NaN      NaN   \n",
       "2   NaN   NaN  ...    NaN   NaN NaN      NaN  NaN   NaN     NaN      NaN   \n",
       "3   NaN   NaN  ...    NaN   NaN NaN      NaN  NaN   NaN     NaN      NaN   \n",
       "4   NaN  33.7  ...    NaN   NaN NaN      NaN  NaN   NaN     NaN      NaN   \n",
       "\n",
       "   Cholesterol  TroponinI  \n",
       "0          NaN        NaN  \n",
       "1          NaN        NaN  \n",
       "2          NaN        NaN  \n",
       "3          NaN        NaN  \n",
       "4          NaN        NaN  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the initial data in parquet format\n",
    "sets_dict_initial = {}\n",
    "sets = [\"a\", \"b\", \"c\"]\n",
    "\n",
    "for set_name in sets:\n",
    "    directory = PROCESSED_DATA_DIR / f\"set_{set_name}.parquet\"\n",
    "    temp_set = pd.read_parquet(directory)\n",
    "    sets_dict_initial[f\"set_{set_name}\"] = temp_set\n",
    "\n",
    "print(sets_dict_initial[\"set_a\"].shape)\n",
    "sets_dict_initial[\"set_a\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a DataFrame following Horn et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def build_TZV_dataframe(original_df, base_time=\"2025-03-10 00:00:00\", duration_hours=48):\n",
    "    df = original_df.copy()\n",
    "\n",
    "    # Convert time to datetime\n",
    "    df[\"Time\"] = pd.to_datetime(df[\"Time\"])\n",
    "    start_time = pd.to_datetime(base_time)\n",
    "    end_time = start_time + pd.Timedelta(hours=duration_hours)\n",
    "\n",
    "    # Normalize time into [0, 1]\n",
    "    total_seconds = (end_time - start_time).total_seconds()\n",
    "    df[\"T\"] = (df[\"Time\"] - start_time).dt.total_seconds() / total_seconds\n",
    "\n",
    "    # Drop RecordID if not needed\n",
    "    feature_cols = [col for col in df.columns if col not in [\"RecordID\", \"Time\", \"T\"]]\n",
    "\n",
    "    # Scale each feature individually (min-max)\n",
    "    scaler = MinMaxScaler()\n",
    "    df_scaled = df[feature_cols].copy()\n",
    "    df_scaled[feature_cols] = scaler.fit_transform(df_scaled[feature_cols])\n",
    "\n",
    "    # Stack into long format\n",
    "    long_df = df_scaled.melt(ignore_index=False, value_vars=feature_cols, var_name=\"Z\", value_name=\"V\")\n",
    "    long_df = long_df.reset_index(drop=True)\n",
    "\n",
    "    # Add corresponding scaled time\n",
    "    repeated_T = np.repeat(df[\"T\"].values, len(feature_cols))\n",
    "    long_df[\"T\"] = repeated_T\n",
    "\n",
    "    # Remove NaNs (measurements not taken)\n",
    "    long_df = long_df.dropna(subset=[\"V\"])\n",
    "\n",
    "    # Map feature names to indices\n",
    "    feature_to_index = {feat: idx for idx, feat in enumerate(feature_cols)}\n",
    "    long_df[\"Z\"] = long_df[\"Z\"].map(feature_to_index)\n",
    "\n",
    "    # Reorder columns\n",
    "    long_df = long_df[[\"T\", \"Z\", \"V\"]].sort_values(\"T\").reset_index(drop=True)\n",
    "\n",
    "    return long_df, feature_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7336640, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T</th>\n",
       "      <th>Z</th>\n",
       "      <th>V</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.547619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.576190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.516364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     T   Z         V\n",
       "0  0.0   0  0.000000\n",
       "1  0.0   9  0.547619\n",
       "2  0.0   9  0.571429\n",
       "3  0.0   9  0.576190\n",
       "4  0.0  16  0.516364"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the TZV dataframes\n",
    "TZV_a, feature_to_index_a = build_TZV_dataframe(sets_dict[\"set_a\"])\n",
    "TZV_b, feature_to_index_b = build_TZV_dataframe(sets_dict[\"set_b\"])\n",
    "TZV_c, feature_to_index_c = build_TZV_dataframe(sets_dict[\"set_c\"])\n",
    "\n",
    "print(TZV_a.shape)\n",
    "TZV_a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-NaN entries in set A: 7336640\n"
     ]
    }
   ],
   "source": [
    "# Count the number of entries in the dataframe that are not NaN, in specified columns\n",
    "def count_non_nan_entries(df, columns):\n",
    "    return df[columns].notnull().sum().sum()\n",
    "\n",
    "specified_columns = [col for col in sets_dict[\"set_a\"].columns if col not in [\"RecordID\", \"Time\"]]\n",
    "non_nan_entries_a = count_non_nan_entries(sets_dict[\"set_a\"], specified_columns)\n",
    "print(f\"Non-NaN entries in set A: {non_nan_entries_a}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe how the numbers match. We know have a row for each of the non NaN values in the original DataFrame. Let's go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use this changed DataFrames to train a Transformer and then evaluate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate new DataLoader and DataSets\n",
    "# What is the y??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = TransformerClassifier(input_size=TZV_a.shape[1]).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "\n",
    "        # Sanity check shapes\n",
    "        assert outputs.shape == batch_y.shape, f\"Shape mismatch: {outputs.shape} vs {batch_y.shape}\"\n",
    "\n",
    "        # Convert to float\n",
    "        batch_y = batch_y.float()\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} | Loss: {running_loss / len(train_loader):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TUM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
